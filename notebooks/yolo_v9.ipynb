{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# YOLO v9を試す\n",
    "今回の課題は物体検出タスクである。  \n",
    "渋谷交差点を定点カメラから撮影した画像を1分ごとに撮影したものだが、実際に用いる際はリアルタイム性が必要だと判断しYOLO v9をベースとして用いる。"
   ],
   "id": "9c8f353131f4957a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:17:08.616516Z",
     "start_time": "2024-06-10T11:17:08.543012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov9c.pt\")"
   ],
   "id": "fba3c1ca9dd4c97c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 物体検出",
   "id": "ab8b5a1e6a7b4346"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:34:41.158500Z",
     "start_time": "2024-06-10T11:18:13.107131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ObjectType(Enum):\n",
    "    \"\"\"YOLOv9上で利用する番号の列挙型\n",
    "    \n",
    "    ex. `ObjectType.person.value` で　`0` が取得できる\n",
    "    \n",
    "    \"\"\"\n",
    "    person = 0\n",
    "    bicycle = 1\n",
    "    car = 2\n",
    "    motorcycle = 3\n",
    "    bus = 5\n",
    "    truck = 7\n",
    "\n",
    "\n",
    "def prepare_dict() -> dict[int, int]:\n",
    "    return {hour: 0 for hour in range(24)}\n",
    "\n",
    "\n",
    "# CSVファイルのヘッダーを作成しておく\n",
    "csv_path = \"../doc/predict.csv\"\n",
    "with open(csv_path, \"w\") as f:\n",
    "    f.write(\"file_name,persons,bicycles,cars,motorcycles,buses,trucks\\n\")\n",
    "\n",
    "sum_dict: dict[str, dict[int, int]] = {\n",
    "    ObjectType.person.name: prepare_dict(),\n",
    "    ObjectType.bicycle.name: prepare_dict(),\n",
    "    ObjectType.car.name: prepare_dict(),\n",
    "    ObjectType.motorcycle.name: prepare_dict(),\n",
    "    ObjectType.bus.name: prepare_dict(),\n",
    "    ObjectType.truck.name: prepare_dict(),\n",
    "}\n",
    "\n",
    "# 1時間ごとに集計して合計値を辞書に格納する\n",
    "for h in range(24):\n",
    "    for m in range(60):\n",
    "\n",
    "        pic_path = f\"../data/20240512/20240512_{str(h).zfill(2)}{str(m).zfill(2)}00.jpg\"\n",
    "        results = model(pic_path, save=True, exist_ok=True, show=False, conf=0.55)\n",
    "\n",
    "        persons, bicycles, cars, motorcycles, buses, trucks = 0, 0, 0, 0, 0, 0\n",
    "        for target in results[0].boxes.cls:\n",
    "            if int(target) == ObjectType.person.value:\n",
    "                sum_dict[ObjectType.person.name][h] += 1\n",
    "                persons += 1\n",
    "            if int(target) == ObjectType.bicycle.value:\n",
    "                sum_dict[ObjectType.bicycle.name][h] += 1\n",
    "                bicycles += 1\n",
    "            if int(target) == ObjectType.car.value:\n",
    "                sum_dict[ObjectType.car.name][h] += 1\n",
    "                cars += 1\n",
    "            if int(target) == ObjectType.motorcycle.value:\n",
    "                sum_dict[ObjectType.motorcycle.name][h] += 1\n",
    "                motorcycles += 1\n",
    "            if int(target) == ObjectType.bus.value:\n",
    "                sum_dict[ObjectType.bus.name][h] += 1\n",
    "                buses += 1\n",
    "            if int(target) == ObjectType.truck.value:\n",
    "                sum_dict[ObjectType.truck.name][h] += 1\n",
    "                trucks += 1\n",
    "        # 当該の時間に検出できなかったものの辞書の値は0として扱う\n",
    "        if persons == 0:\n",
    "            sum_dict[ObjectType.person.name][h] = 0\n",
    "        if bicycles == 0:\n",
    "            sum_dict[ObjectType.bicycle.name][h] = 0\n",
    "        if cars == 0:\n",
    "            sum_dict[ObjectType.car.name][h] = 0\n",
    "        if motorcycles == 0:\n",
    "            sum_dict[ObjectType.motorcycle.name][h] = 0\n",
    "        if buses == 0:\n",
    "            sum_dict[ObjectType.bus.name][h] = 0\n",
    "        if trucks == 0:\n",
    "            sum_dict[ObjectType.truck.name][h] = 0\n",
    "\n",
    "        # 処理したファイルで検出された物体の数をCSVに追記する\n",
    "        with open(csv_path, \"a\") as f:\n",
    "            f.write(f\"20240512/20240512_{str(h).zfill(2)}{str(m).zfill(2)}00.jpg,{persons},{bicycles},{cars},{motorcycles},{buses},{trucks}\\n\")"
   ],
   "id": "e11eea75c906f323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000000.jpg: 384x640 2 cars, 706.2ms\n",
      "Speed: 2.0ms preprocess, 706.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000100.jpg: 384x640 5 cars, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000200.jpg: 384x640 2 cars, 1 tv, 685.1ms\n",
      "Speed: 1.0ms preprocess, 685.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000300.jpg: 384x640 6 cars, 1 truck, 1 tv, 686.2ms\n",
      "Speed: 1.0ms preprocess, 686.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000400.jpg: 384x640 (no detections), 683.1ms\n",
      "Speed: 1.0ms preprocess, 683.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000500.jpg: 384x640 9 cars, 669.8ms\n",
      "Speed: 1.0ms preprocess, 669.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000600.jpg: 384x640 4 cars, 666.2ms\n",
      "Speed: 1.0ms preprocess, 666.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000700.jpg: 384x640 6 cars, 668.6ms\n",
      "Speed: 2.0ms preprocess, 668.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000800.jpg: 384x640 4 cars, 1 tv, 688.6ms\n",
      "Speed: 1.0ms preprocess, 688.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_000900.jpg: 384x640 2 cars, 678.6ms\n",
      "Speed: 1.0ms preprocess, 678.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001000.jpg: 384x640 1 person, 2 cars, 1 tv, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001100.jpg: 384x640 9 cars, 688.6ms\n",
      "Speed: 1.0ms preprocess, 688.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001200.jpg: 384x640 3 cars, 657.6ms\n",
      "Speed: 1.0ms preprocess, 657.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001300.jpg: 384x640 5 cars, 1 truck, 1 tv, 657.7ms\n",
      "Speed: 1.0ms preprocess, 657.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001400.jpg: 384x640 1 car, 1 traffic light, 662.9ms\n",
      "Speed: 1.0ms preprocess, 662.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001500.jpg: 384x640 4 cars, 659.1ms\n",
      "Speed: 1.0ms preprocess, 659.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001600.jpg: 384x640 3 cars, 660.2ms\n",
      "Speed: 1.0ms preprocess, 660.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001700.jpg: 384x640 4 cars, 700.7ms\n",
      "Speed: 1.0ms preprocess, 700.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001800.jpg: 384x640 3 cars, 681.1ms\n",
      "Speed: 1.0ms preprocess, 681.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_001900.jpg: 384x640 6 cars, 658.0ms\n",
      "Speed: 1.0ms preprocess, 658.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002000.jpg: 384x640 4 cars, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002100.jpg: 384x640 4 cars, 658.0ms\n",
      "Speed: 1.0ms preprocess, 658.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002200.jpg: 384x640 1 car, 1 tv, 661.7ms\n",
      "Speed: 1.0ms preprocess, 661.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002300.jpg: 384x640 7 cars, 710.6ms\n",
      "Speed: 1.0ms preprocess, 710.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002400.jpg: 384x640 6 cars, 1 tv, 659.7ms\n",
      "Speed: 1.0ms preprocess, 659.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002500.jpg: 384x640 5 cars, 654.4ms\n",
      "Speed: 1.0ms preprocess, 654.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002600.jpg: 384x640 5 cars, 1 tv, 652.1ms\n",
      "Speed: 1.0ms preprocess, 652.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002700.jpg: 384x640 6 cars, 1 tv, 651.9ms\n",
      "Speed: 1.0ms preprocess, 651.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002800.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_002900.jpg: 384x640 3 persons, 5 cars, 2 traffic lights, 653.2ms\n",
      "Speed: 1.0ms preprocess, 653.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003000.jpg: 384x640 1 person, 2 cars, 1 traffic light, 1 tv, 682.2ms\n",
      "Speed: 1.0ms preprocess, 682.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003100.jpg: 384x640 6 cars, 1 traffic light, 672.1ms\n",
      "Speed: 2.0ms preprocess, 672.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003200.jpg: 384x640 2 cars, 655.1ms\n",
      "Speed: 1.0ms preprocess, 655.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003300.jpg: 384x640 5 cars, 1 tv, 654.7ms\n",
      "Speed: 1.0ms preprocess, 654.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003400.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 652.6ms\n",
      "Speed: 1.0ms preprocess, 652.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003500.jpg: 384x640 6 cars, 654.0ms\n",
      "Speed: 1.0ms preprocess, 654.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003600.jpg: 384x640 5 cars, 652.1ms\n",
      "Speed: 2.0ms preprocess, 652.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003700.jpg: 384x640 4 cars, 1 traffic light, 1 tv, 655.6ms\n",
      "Speed: 1.0ms preprocess, 655.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003800.jpg: 384x640 2 cars, 1 tv, 657.6ms\n",
      "Speed: 1.0ms preprocess, 657.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_003900.jpg: 384x640 3 cars, 660.0ms\n",
      "Speed: 1.0ms preprocess, 660.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004000.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 655.2ms\n",
      "Speed: 1.0ms preprocess, 655.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004100.jpg: 384x640 4 cars, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004200.jpg: 384x640 1 person, 1 car, 1 traffic light, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004300.jpg: 384x640 1 car, 650.9ms\n",
      "Speed: 1.0ms preprocess, 650.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004400.jpg: 384x640 2 persons, 1 car, 1 traffic light, 656.3ms\n",
      "Speed: 1.0ms preprocess, 656.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004500.jpg: 384x640 (no detections), 669.1ms\n",
      "Speed: 2.0ms preprocess, 669.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004600.jpg: 384x640 2 persons, 1 car, 656.9ms\n",
      "Speed: 1.0ms preprocess, 656.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004700.jpg: 384x640 1 car, 1 truck, 660.6ms\n",
      "Speed: 1.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004800.jpg: 384x640 4 cars, 655.7ms\n",
      "Speed: 1.0ms preprocess, 655.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_004900.jpg: 384x640 2 persons, 4 cars, 674.2ms\n",
      "Speed: 1.0ms preprocess, 674.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005000.jpg: 384x640 1 person, 1 car, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005100.jpg: 384x640 2 persons, 6 cars, 653.1ms\n",
      "Speed: 1.0ms preprocess, 653.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005200.jpg: 384x640 2 persons, 3 cars, 652.8ms\n",
      "Speed: 1.0ms preprocess, 652.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005300.jpg: 384x640 3 cars, 658.8ms\n",
      "Speed: 1.0ms preprocess, 658.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005400.jpg: 384x640 1 person, 1 car, 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005500.jpg: 384x640 4 cars, 666.2ms\n",
      "Speed: 1.0ms preprocess, 666.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005600.jpg: 384x640 1 person, 2 cars, 1 truck, 658.3ms\n",
      "Speed: 1.5ms preprocess, 658.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005700.jpg: 384x640 4 cars, 2 trucks, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005800.jpg: 384x640 1 person, 4 cars, 695.1ms\n",
      "Speed: 1.0ms preprocess, 695.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_005900.jpg: 384x640 1 person, 4 cars, 1 traffic light, 664.5ms\n",
      "Speed: 1.0ms preprocess, 664.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010000.jpg: 384x640 1 person, 6 cars, 657.5ms\n",
      "Speed: 1.0ms preprocess, 657.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010100.jpg: 384x640 7 cars, 662.0ms\n",
      "Speed: 1.0ms preprocess, 662.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010200.jpg: 384x640 6 cars, 663.0ms\n",
      "Speed: 1.0ms preprocess, 663.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010300.jpg: 384x640 9 cars, 659.5ms\n",
      "Speed: 1.0ms preprocess, 659.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010400.jpg: 384x640 8 cars, 658.5ms\n",
      "Speed: 1.0ms preprocess, 658.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010500.jpg: 384x640 1 person, 6 cars, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010600.jpg: 384x640 4 cars, 1 traffic light, 683.6ms\n",
      "Speed: 1.0ms preprocess, 683.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010700.jpg: 384x640 9 cars, 661.0ms\n",
      "Speed: 1.0ms preprocess, 661.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010800.jpg: 384x640 4 persons, 4 cars, 2 traffic lights, 660.0ms\n",
      "Speed: 1.0ms preprocess, 660.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_010900.jpg: 384x640 1 person, 5 cars, 659.5ms\n",
      "Speed: 1.0ms preprocess, 659.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011000.jpg: 384x640 2 persons, 4 cars, 1 bus, 1 traffic light, 664.5ms\n",
      "Speed: 1.0ms preprocess, 664.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011100.jpg: 384x640 6 cars, 1 bus, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011200.jpg: 384x640 2 persons, 3 cars, 654.0ms\n",
      "Speed: 1.0ms preprocess, 654.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011300.jpg: 384x640 1 person, 10 cars, 658.0ms\n",
      "Speed: 1.0ms preprocess, 658.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011400.jpg: 384x640 5 cars, 1 traffic light, 660.5ms\n",
      "Speed: 1.0ms preprocess, 660.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011500.jpg: 384x640 2 persons, 10 cars, 1 bus, 1 truck, 659.5ms\n",
      "Speed: 0.0ms preprocess, 659.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011600.jpg: 384x640 1 person, 7 cars, 658.5ms\n",
      "Speed: 1.0ms preprocess, 658.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011700.jpg: 384x640 2 persons, 10 cars, 656.0ms\n",
      "Speed: 1.0ms preprocess, 656.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011800.jpg: 384x640 4 cars, 1 traffic light, 657.0ms\n",
      "Speed: 1.0ms preprocess, 657.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_011900.jpg: 384x640 14 cars, 661.5ms\n",
      "Speed: 1.0ms preprocess, 661.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012000.jpg: 384x640 6 cars, 2 traffic lights, 657.5ms\n",
      "Speed: 1.0ms preprocess, 657.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012100.jpg: 384x640 7 cars, 655.5ms\n",
      "Speed: 1.0ms preprocess, 655.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012200.jpg: 384x640 6 cars, 656.0ms\n",
      "Speed: 1.0ms preprocess, 656.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012300.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 659.5ms\n",
      "Speed: 1.0ms preprocess, 659.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012400.jpg: 384x640 6 persons, 3 cars, 2 traffic lights, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012500.jpg: 384x640 3 cars, 1 traffic light, 691.6ms\n",
      "Speed: 1.0ms preprocess, 691.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012600.jpg: 384x640 8 cars, 689.6ms\n",
      "Speed: 0.0ms preprocess, 689.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012700.jpg: 384x640 9 cars, 1 bus, 2 traffic lights, 683.6ms\n",
      "Speed: 1.0ms preprocess, 683.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012800.jpg: 384x640 3 cars, 693.2ms\n",
      "Speed: 1.0ms preprocess, 693.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_012900.jpg: 384x640 5 cars, 659.0ms\n",
      "Speed: 1.0ms preprocess, 659.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013000.jpg: 384x640 1 person, 5 cars, 654.6ms\n",
      "Speed: 1.0ms preprocess, 654.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013100.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 661.6ms\n",
      "Speed: 1.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013200.jpg: 384x640 1 person, 4 cars, 1 bus, 1 traffic light, 659.0ms\n",
      "Speed: 1.0ms preprocess, 659.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013300.jpg: 384x640 5 cars, 1 traffic light, 683.0ms\n",
      "Speed: 1.0ms preprocess, 683.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013400.jpg: 384x640 1 person, 4 cars, 1 traffic light, 678.6ms\n",
      "Speed: 1.0ms preprocess, 678.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013500.jpg: 384x640 1 person, 6 cars, 1 traffic light, 680.6ms\n",
      "Speed: 1.0ms preprocess, 680.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013600.jpg: 384x640 6 cars, 673.0ms\n",
      "Speed: 1.0ms preprocess, 673.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013700.jpg: 384x640 1 person, 11 cars, 671.0ms\n",
      "Speed: 1.0ms preprocess, 671.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013800.jpg: 384x640 6 cars, 1 traffic light, 679.0ms\n",
      "Speed: 1.0ms preprocess, 679.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_013900.jpg: 384x640 4 cars, 1 traffic light, 718.6ms\n",
      "Speed: 1.0ms preprocess, 718.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014000.jpg: 384x640 1 person, 4 cars, 712.4ms\n",
      "Speed: 1.0ms preprocess, 712.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014100.jpg: 384x640 8 cars, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014200.jpg: 384x640 1 person, 7 cars, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014300.jpg: 384x640 2 persons, 6 cars, 696.7ms\n",
      "Speed: 1.0ms preprocess, 696.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014400.jpg: 384x640 2 persons, 3 cars, 1 tv, 705.6ms\n",
      "Speed: 1.0ms preprocess, 705.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014500.jpg: 384x640 6 cars, 1 bus, 704.2ms\n",
      "Speed: 1.0ms preprocess, 704.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014600.jpg: 384x640 1 person, 4 cars, 682.6ms\n",
      "Speed: 1.0ms preprocess, 682.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014700.jpg: 384x640 1 person, 5 cars, 683.6ms\n",
      "Speed: 1.0ms preprocess, 683.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014800.jpg: 384x640 1 person, 2 cars, 1 traffic light, 684.6ms\n",
      "Speed: 1.0ms preprocess, 684.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_014900.jpg: 384x640 3 cars, 706.6ms\n",
      "Speed: 2.0ms preprocess, 706.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015000.jpg: 384x640 1 person, 3 cars, 684.6ms\n",
      "Speed: 1.0ms preprocess, 684.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015100.jpg: 384x640 5 cars, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015200.jpg: 384x640 1 person, 6 cars, 1 traffic light, 685.6ms\n",
      "Speed: 1.0ms preprocess, 685.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015300.jpg: 384x640 4 cars, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015400.jpg: 384x640 4 cars, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015500.jpg: 384x640 5 cars, 1 traffic light, 707.1ms\n",
      "Speed: 1.0ms preprocess, 707.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015600.jpg: 384x640 1 person, 7 cars, 682.0ms\n",
      "Speed: 1.5ms preprocess, 682.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015700.jpg: 384x640 1 person, 6 cars, 681.0ms\n",
      "Speed: 1.0ms preprocess, 681.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015800.jpg: 384x640 2 cars, 2 traffic lights, 671.0ms\n",
      "Speed: 1.0ms preprocess, 671.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_015900.jpg: 384x640 4 cars, 674.5ms\n",
      "Speed: 1.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020000.jpg: 384x640 5 cars, 1 traffic light, 662.5ms\n",
      "Speed: 1.0ms preprocess, 662.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020100.jpg: 384x640 1 person, 5 cars, 1 truck, 674.5ms\n",
      "Speed: 1.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020200.jpg: 384x640 2 persons, 3 cars, 676.5ms\n",
      "Speed: 1.0ms preprocess, 676.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020300.jpg: 384x640 1 person, 6 cars, 1 traffic light, 684.5ms\n",
      "Speed: 1.0ms preprocess, 684.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020400.jpg: 384x640 1 car, 1 traffic light, 673.6ms\n",
      "Speed: 2.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020500.jpg: 384x640 1 person, 1 car, 1 traffic light, 680.6ms\n",
      "Speed: 2.0ms preprocess, 680.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020600.jpg: 384x640 6 cars, 659.6ms\n",
      "Speed: 1.0ms preprocess, 659.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020700.jpg: 384x640 5 cars, 696.1ms\n",
      "Speed: 1.0ms preprocess, 696.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020800.jpg: 384x640 2 cars, 2 traffic lights, 759.7ms\n",
      "Speed: 1.0ms preprocess, 759.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_020900.jpg: 384x640 5 cars, 1 traffic light, 716.6ms\n",
      "Speed: 1.0ms preprocess, 716.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021000.jpg: 384x640 5 cars, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021100.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 715.3ms\n",
      "Speed: 1.0ms preprocess, 715.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021200.jpg: 384x640 1 person, 3 cars, 689.6ms\n",
      "Speed: 1.0ms preprocess, 689.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021300.jpg: 384x640 1 person, 4 cars, 694.1ms\n",
      "Speed: 1.0ms preprocess, 694.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021400.jpg: 384x640 6 cars, 697.1ms\n",
      "Speed: 1.0ms preprocess, 697.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021500.jpg: 384x640 7 cars, 1 traffic light, 767.2ms\n",
      "Speed: 1.0ms preprocess, 767.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021600.jpg: 384x640 2 persons, 5 cars, 1 bus, 1 traffic light, 688.6ms\n",
      "Speed: 2.0ms preprocess, 688.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021700.jpg: 384x640 1 person, 5 cars, 693.6ms\n",
      "Speed: 1.0ms preprocess, 693.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021800.jpg: 384x640 2 cars, 1 traffic light, 707.1ms\n",
      "Speed: 1.0ms preprocess, 707.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_021900.jpg: 384x640 6 cars, 2 traffic lights, 678.0ms\n",
      "Speed: 1.0ms preprocess, 678.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022000.jpg: 384x640 1 person, 5 cars, 1 tv, 683.6ms\n",
      "Speed: 2.0ms preprocess, 683.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022100.jpg: 384x640 4 cars, 1 traffic light, 680.1ms\n",
      "Speed: 1.0ms preprocess, 680.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022200.jpg: 384x640 2 persons, 4 cars, 684.5ms\n",
      "Speed: 2.0ms preprocess, 684.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022300.jpg: 384x640 4 cars, 672.0ms\n",
      "Speed: 1.0ms preprocess, 672.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022400.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 672.0ms\n",
      "Speed: 1.0ms preprocess, 672.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022500.jpg: 384x640 3 cars, 671.1ms\n",
      "Speed: 1.0ms preprocess, 671.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022600.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 659.0ms\n",
      "Speed: 1.0ms preprocess, 659.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022700.jpg: 384x640 3 cars, 656.6ms\n",
      "Speed: 1.0ms preprocess, 656.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022800.jpg: 384x640 2 cars, 1 tv, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_022900.jpg: 384x640 1 person, 4 cars, 662.0ms\n",
      "Speed: 1.0ms preprocess, 662.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023000.jpg: 384x640 2 persons, 1 car, 1 traffic light, 659.0ms\n",
      "Speed: 1.0ms preprocess, 659.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023100.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 660.5ms\n",
      "Speed: 1.0ms preprocess, 660.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023200.jpg: 384x640 2 persons, 2 cars, 682.6ms\n",
      "Speed: 1.0ms preprocess, 682.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023300.jpg: 384x640 4 cars, 664.6ms\n",
      "Speed: 0.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023400.jpg: 384x640 1 car, 1 traffic light, 693.6ms\n",
      "Speed: 1.0ms preprocess, 693.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023500.jpg: 384x640 1 person, 2 cars, 660.5ms\n",
      "Speed: 1.0ms preprocess, 660.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023600.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 678.5ms\n",
      "Speed: 1.0ms preprocess, 678.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023700.jpg: 384x640 1 car, 666.5ms\n",
      "Speed: 1.0ms preprocess, 666.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023800.jpg: 384x640 1 person, 2 cars, 662.0ms\n",
      "Speed: 1.0ms preprocess, 662.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_023900.jpg: 384x640 1 person, 2 cars, 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024000.jpg: 384x640 1 person, 1 car, 672.0ms\n",
      "Speed: 1.0ms preprocess, 672.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024100.jpg: 384x640 2 cars, 1 traffic light, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024200.jpg: 384x640 2 persons, 2 cars, 662.5ms\n",
      "Speed: 1.0ms preprocess, 662.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024300.jpg: 384x640 2 persons, 4 cars, 1 traffic light, 658.5ms\n",
      "Speed: 1.0ms preprocess, 658.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024400.jpg: 384x640 3 cars, 656.0ms\n",
      "Speed: 1.0ms preprocess, 656.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024500.jpg: 384x640 2 persons, 2 cars, 1 truck, 1 traffic light, 651.0ms\n",
      "Speed: 1.0ms preprocess, 651.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024600.jpg: 384x640 1 person, 1 car, 655.5ms\n",
      "Speed: 1.0ms preprocess, 655.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024700.jpg: 384x640 2 persons, 5 cars, 1 traffic light, 651.5ms\n",
      "Speed: 1.0ms preprocess, 651.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024800.jpg: 384x640 1 person, 2 cars, 1 traffic light, 647.0ms\n",
      "Speed: 1.0ms preprocess, 647.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_024900.jpg: 384x640 2 persons, 1 traffic light, 656.0ms\n",
      "Speed: 1.0ms preprocess, 656.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025000.jpg: 384x640 2 persons, 2 cars, 650.5ms\n",
      "Speed: 1.0ms preprocess, 650.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025100.jpg: 384x640 2 cars, 1 traffic light, 648.9ms\n",
      "Speed: 1.0ms preprocess, 648.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025200.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 652.0ms\n",
      "Speed: 1.0ms preprocess, 652.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025300.jpg: 384x640 2 cars, 652.6ms\n",
      "Speed: 1.0ms preprocess, 652.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025400.jpg: 384x640 2 cars, 1 traffic light, 672.7ms\n",
      "Speed: 1.0ms preprocess, 672.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025500.jpg: 384x640 1 car, 654.5ms\n",
      "Speed: 1.0ms preprocess, 654.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025600.jpg: 384x640 2 cars, 650.1ms\n",
      "Speed: 1.0ms preprocess, 650.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025700.jpg: 384x640 3 persons, 1 car, 652.9ms\n",
      "Speed: 1.0ms preprocess, 652.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025800.jpg: 384x640 2 cars, 1 traffic light, 661.1ms\n",
      "Speed: 1.0ms preprocess, 661.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_025900.jpg: 384x640 3 persons, 4 cars, 649.2ms\n",
      "Speed: 1.0ms preprocess, 649.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030000.jpg: 384x640 1 person, 2 cars, 646.8ms\n",
      "Speed: 1.0ms preprocess, 646.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030100.jpg: 384x640 4 cars, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030200.jpg: 384x640 1 person, 4 cars, 1 traffic light, 679.7ms\n",
      "Speed: 1.0ms preprocess, 679.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030300.jpg: 384x640 1 person, 6 cars, 1 traffic light, 680.7ms\n",
      "Speed: 1.0ms preprocess, 680.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030400.jpg: 384x640 1 person, 4 cars, 1 traffic light, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030500.jpg: 384x640 1 person, 4 cars, 655.6ms\n",
      "Speed: 1.0ms preprocess, 655.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030600.jpg: 384x640 2 persons, 4 cars, 649.2ms\n",
      "Speed: 1.0ms preprocess, 649.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030700.jpg: 384x640 2 cars, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030800.jpg: 384x640 2 persons, 3 cars, 1 tv, 676.7ms\n",
      "Speed: 1.0ms preprocess, 676.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_030900.jpg: 384x640 2 cars, 670.7ms\n",
      "Speed: 1.0ms preprocess, 670.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031000.jpg: 384x640 2 persons, 3 cars, 1 truck, 1 traffic light, 672.8ms\n",
      "Speed: 1.0ms preprocess, 672.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031100.jpg: 384x640 2 cars, 1 truck, 2 traffic lights, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031200.jpg: 384x640 1 person, 4 cars, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031300.jpg: 384x640 1 person, 6 cars, 1 traffic light, 652.1ms\n",
      "Speed: 1.0ms preprocess, 652.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031400.jpg: 384x640 3 persons, 2 cars, 652.7ms\n",
      "Speed: 1.0ms preprocess, 652.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031500.jpg: 384x640 1 person, 1 car, 644.8ms\n",
      "Speed: 1.0ms preprocess, 644.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031600.jpg: 384x640 1 person, 1 car, 680.7ms\n",
      "Speed: 1.0ms preprocess, 680.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031700.jpg: 384x640 5 cars, 647.4ms\n",
      "Speed: 1.0ms preprocess, 647.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031800.jpg: 384x640 7 cars, 1 traffic light, 644.3ms\n",
      "Speed: 1.0ms preprocess, 644.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_031900.jpg: 384x640 5 cars, 1 truck, 647.8ms\n",
      "Speed: 1.0ms preprocess, 647.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032000.jpg: 384x640 1 car, 1 traffic light, 645.5ms\n",
      "Speed: 1.0ms preprocess, 645.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032100.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 647.1ms\n",
      "Speed: 1.1ms preprocess, 647.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032200.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 648.9ms\n",
      "Speed: 1.0ms preprocess, 648.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032300.jpg: 384x640 1 person, 647.3ms\n",
      "Speed: 1.0ms preprocess, 647.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032400.jpg: 384x640 1 person, 6 cars, 643.2ms\n",
      "Speed: 1.5ms preprocess, 643.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032500.jpg: 384x640 3 cars, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032600.jpg: 384x640 4 cars, 646.2ms\n",
      "Speed: 1.0ms preprocess, 646.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032700.jpg: 384x640 1 person, 2 cars, 648.8ms\n",
      "Speed: 1.0ms preprocess, 648.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032800.jpg: 384x640 4 cars, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_032900.jpg: 384x640 1 person, 2 cars, 1 truck, 1 traffic light, 645.3ms\n",
      "Speed: 1.0ms preprocess, 645.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033000.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 636.8ms\n",
      "Speed: 1.0ms preprocess, 636.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033100.jpg: 384x640 1 car, 637.4ms\n",
      "Speed: 1.0ms preprocess, 637.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033200.jpg: 384x640 1 person, 2 traffic lights, 645.9ms\n",
      "Speed: 1.0ms preprocess, 645.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033300.jpg: 384x640 1 person, 2 cars, 1 truck, 644.9ms\n",
      "Speed: 1.0ms preprocess, 644.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033400.jpg: 384x640 1 person, 2 cars, 644.3ms\n",
      "Speed: 1.0ms preprocess, 644.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033500.jpg: 384x640 2 cars, 645.8ms\n",
      "Speed: 1.0ms preprocess, 645.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033600.jpg: 384x640 2 cars, 645.2ms\n",
      "Speed: 1.0ms preprocess, 645.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033700.jpg: 384x640 2 cars, 648.2ms\n",
      "Speed: 1.0ms preprocess, 648.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033800.jpg: 384x640 2 persons, 4 cars, 656.7ms\n",
      "Speed: 1.0ms preprocess, 656.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_033900.jpg: 384x640 4 cars, 2 traffic lights, 659.6ms\n",
      "Speed: 1.0ms preprocess, 659.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034000.jpg: 384x640 2 persons, 651.2ms\n",
      "Speed: 0.0ms preprocess, 651.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034100.jpg: 384x640 1 car, 2 traffic lights, 646.3ms\n",
      "Speed: 1.0ms preprocess, 646.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034200.jpg: 384x640 1 car, 650.5ms\n",
      "Speed: 1.0ms preprocess, 650.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034300.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 648.3ms\n",
      "Speed: 1.0ms preprocess, 648.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034400.jpg: 384x640 1 person, 650.2ms\n",
      "Speed: 1.0ms preprocess, 650.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034500.jpg: 384x640 1 person, 5 cars, 645.8ms\n",
      "Speed: 0.0ms preprocess, 645.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034600.jpg: 384x640 1 person, 4 cars, 1 truck, 1 traffic light, 658.7ms\n",
      "Speed: 1.0ms preprocess, 658.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034700.jpg: 384x640 1 person, 2 cars, 1 truck, 665.2ms\n",
      "Speed: 2.0ms preprocess, 665.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034800.jpg: 384x640 1 person, 2 cars, 1 truck, 1 traffic light, 648.3ms\n",
      "Speed: 1.0ms preprocess, 648.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_034900.jpg: 384x640 1 person, 3 cars, 1 truck, 647.0ms\n",
      "Speed: 1.0ms preprocess, 647.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035000.jpg: 384x640 1 person, 2 cars, 1 truck, 649.2ms\n",
      "Speed: 1.0ms preprocess, 649.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035100.jpg: 384x640 1 car, 1 truck, 649.4ms\n",
      "Speed: 1.0ms preprocess, 649.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035200.jpg: 384x640 3 persons, 1 tv, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035300.jpg: 384x640 2 persons, 1 traffic light, 686.5ms\n",
      "Speed: 1.0ms preprocess, 686.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035400.jpg: 384x640 1 traffic light, 658.5ms\n",
      "Speed: 1.0ms preprocess, 658.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035500.jpg: 384x640 1 car, 1 bus, 655.0ms\n",
      "Speed: 1.0ms preprocess, 655.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035600.jpg: 384x640 1 car, 651.0ms\n",
      "Speed: 1.0ms preprocess, 651.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035700.jpg: 384x640 1 person, 1 car, 652.5ms\n",
      "Speed: 1.0ms preprocess, 652.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035800.jpg: 384x640 4 persons, 648.0ms\n",
      "Speed: 1.0ms preprocess, 648.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_035900.jpg: 384x640 1 traffic light, 653.0ms\n",
      "Speed: 1.0ms preprocess, 653.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040000.jpg: 384x640 3 persons, 3 cars, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040100.jpg: 384x640 1 person, 4 cars, 691.1ms\n",
      "Speed: 1.0ms preprocess, 691.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040200.jpg: 384x640 2 persons, 1 car, 653.5ms\n",
      "Speed: 1.0ms preprocess, 653.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040300.jpg: 384x640 1 car, 1 traffic light, 657.5ms\n",
      "Speed: 1.0ms preprocess, 657.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040400.jpg: 384x640 2 cars, 1 traffic light, 652.0ms\n",
      "Speed: 1.0ms preprocess, 652.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040500.jpg: 384x640 1 car, 656.0ms\n",
      "Speed: 1.0ms preprocess, 656.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040600.jpg: 384x640 4 persons, 2 cars, 2 traffic lights, 650.5ms\n",
      "Speed: 1.0ms preprocess, 650.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040700.jpg: 384x640 1 person, 3 cars, 651.5ms\n",
      "Speed: 1.0ms preprocess, 651.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040800.jpg: 384x640 1 person, 3 cars, 656.0ms\n",
      "Speed: 1.0ms preprocess, 656.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_040900.jpg: 384x640 1 person, 2 cars, 651.5ms\n",
      "Speed: 1.0ms preprocess, 651.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041000.jpg: 384x640 1 person, 4 cars, 1 traffic light, 654.5ms\n",
      "Speed: 1.0ms preprocess, 654.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041100.jpg: 384x640 2 persons, 3 cars, 653.0ms\n",
      "Speed: 1.0ms preprocess, 653.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041200.jpg: 384x640 3 cars, 1 traffic light, 650.0ms\n",
      "Speed: 1.0ms preprocess, 650.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041300.jpg: 384x640 6 cars, 653.5ms\n",
      "Speed: 1.0ms preprocess, 653.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041400.jpg: 384x640 1 person, 2 cars, 648.5ms\n",
      "Speed: 1.0ms preprocess, 648.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041500.jpg: 384x640 1 person, 3 cars, 1 traffic light, 648.0ms\n",
      "Speed: 1.0ms preprocess, 648.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041600.jpg: 384x640 2 cars, 1 traffic light, 651.5ms\n",
      "Speed: 1.0ms preprocess, 651.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041700.jpg: 384x640 2 persons, 1 car, 1 truck, 646.5ms\n",
      "Speed: 1.0ms preprocess, 646.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041800.jpg: 384x640 2 cars, 1 traffic light, 652.0ms\n",
      "Speed: 1.0ms preprocess, 652.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_041900.jpg: 384x640 3 cars, 649.6ms\n",
      "Speed: 1.0ms preprocess, 649.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042000.jpg: 384x640 1 person, 2 cars, 1 traffic light, 652.6ms\n",
      "Speed: 1.0ms preprocess, 652.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042100.jpg: 384x640 3 persons, 2 cars, 650.0ms\n",
      "Speed: 1.0ms preprocess, 650.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042200.jpg: 384x640 1 car, 653.0ms\n",
      "Speed: 1.0ms preprocess, 653.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042300.jpg: 384x640 1 person, 1 car, 680.6ms\n",
      "Speed: 1.0ms preprocess, 680.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042400.jpg: 384x640 3 cars, 658.6ms\n",
      "Speed: 1.0ms preprocess, 658.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042500.jpg: 384x640 4 persons, 6 cars, 648.5ms\n",
      "Speed: 1.0ms preprocess, 648.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042600.jpg: 384x640 1 person, 2 cars, 1 traffic light, 650.0ms\n",
      "Speed: 1.0ms preprocess, 650.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042700.jpg: 384x640 2 persons, 2 cars, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042800.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 651.5ms\n",
      "Speed: 1.0ms preprocess, 651.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_042900.jpg: 384x640 2 persons, 2 cars, 653.0ms\n",
      "Speed: 1.0ms preprocess, 653.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043000.jpg: 384x640 4 persons, 5 cars, 652.0ms\n",
      "Speed: 1.0ms preprocess, 652.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043100.jpg: 384x640 3 cars, 657.6ms\n",
      "Speed: 1.0ms preprocess, 657.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043200.jpg: 384x640 3 persons, 2 cars, 650.5ms\n",
      "Speed: 1.0ms preprocess, 650.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043300.jpg: 384x640 1 person, 4 cars, 649.0ms\n",
      "Speed: 1.0ms preprocess, 649.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043400.jpg: 384x640 3 persons, 2 cars, 648.5ms\n",
      "Speed: 1.0ms preprocess, 648.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043500.jpg: 384x640 1 person, 5 cars, 1 bus, 652.5ms\n",
      "Speed: 1.0ms preprocess, 652.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043600.jpg: 384x640 4 cars, 1 bus, 649.0ms\n",
      "Speed: 1.0ms preprocess, 649.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043700.jpg: 384x640 2 cars, 650.0ms\n",
      "Speed: 1.0ms preprocess, 650.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043800.jpg: 384x640 2 cars, 652.5ms\n",
      "Speed: 1.0ms preprocess, 652.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_043900.jpg: 384x640 2 persons, 1 car, 1 truck, 648.0ms\n",
      "Speed: 1.0ms preprocess, 648.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044000.jpg: 384x640 2 persons, 4 cars, 649.0ms\n",
      "Speed: 1.0ms preprocess, 649.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044100.jpg: 384x640 2 cars, 652.5ms\n",
      "Speed: 1.0ms preprocess, 652.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044200.jpg: 384x640 1 person, 2 cars, 649.0ms\n",
      "Speed: 1.0ms preprocess, 649.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044300.jpg: 384x640 1 person, 2 cars, 1 truck, 647.0ms\n",
      "Speed: 1.0ms preprocess, 647.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044400.jpg: 384x640 2 persons, 2 cars, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044500.jpg: 384x640 1 person, 3 cars, 663.2ms\n",
      "Speed: 1.0ms preprocess, 663.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044600.jpg: 384x640 1 person, 5 cars, 1 truck, 670.5ms\n",
      "Speed: 1.0ms preprocess, 670.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044700.jpg: 384x640 1 person, 2 cars, 1 truck, 651.0ms\n",
      "Speed: 1.0ms preprocess, 651.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044800.jpg: 384x640 2 persons, 4 cars, 1 bus, 1 truck, 655.5ms\n",
      "Speed: 1.0ms preprocess, 655.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_044900.jpg: 384x640 2 persons, 2 cars, 2 traffic lights, 650.5ms\n",
      "Speed: 1.0ms preprocess, 650.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045000.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 651.0ms\n",
      "Speed: 1.0ms preprocess, 651.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045100.jpg: 384x640 1 person, 1 car, 1 bus, 647.0ms\n",
      "Speed: 1.0ms preprocess, 647.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045200.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 648.5ms\n",
      "Speed: 1.0ms preprocess, 648.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045300.jpg: 384x640 2 persons, 2 cars, 2 trucks, 651.0ms\n",
      "Speed: 1.0ms preprocess, 651.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045400.jpg: 384x640 1 car, 1 truck, 649.0ms\n",
      "Speed: 1.0ms preprocess, 649.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045500.jpg: 384x640 3 persons, 1 car, 1 truck, 649.5ms\n",
      "Speed: 2.0ms preprocess, 649.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045600.jpg: 384x640 2 persons, 2 cars, 652.5ms\n",
      "Speed: 1.0ms preprocess, 652.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045700.jpg: 384x640 2 cars, 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045800.jpg: 384x640 1 person, 2 cars, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_045900.jpg: 384x640 1 person, 3 cars, 1 truck, 648.6ms\n",
      "Speed: 1.0ms preprocess, 648.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050000.jpg: 384x640 1 person, 2 cars, 648.1ms\n",
      "Speed: 1.0ms preprocess, 648.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050100.jpg: 384x640 4 cars, 642.6ms\n",
      "Speed: 1.0ms preprocess, 642.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050200.jpg: 384x640 1 person, 4 cars, 647.1ms\n",
      "Speed: 1.0ms preprocess, 647.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050300.jpg: 384x640 1 truck, 642.0ms\n",
      "Speed: 1.0ms preprocess, 642.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050400.jpg: 384x640 1 person, 4 cars, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050500.jpg: 384x640 1 car, 1 bus, 644.0ms\n",
      "Speed: 1.0ms preprocess, 644.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050600.jpg: 384x640 3 persons, 3 cars, 646.1ms\n",
      "Speed: 1.0ms preprocess, 646.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050700.jpg: 384x640 1 person, 2 cars, 643.6ms\n",
      "Speed: 1.0ms preprocess, 643.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050800.jpg: 384x640 2 cars, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_050900.jpg: 384x640 2 persons, 2 cars, 638.0ms\n",
      "Speed: 1.0ms preprocess, 638.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051000.jpg: 384x640 2 persons, 3 cars, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051100.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051200.jpg: 384x640 1 car, 644.0ms\n",
      "Speed: 1.0ms preprocess, 644.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051300.jpg: 384x640 1 car, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051400.jpg: 384x640 2 cars, 1 traffic light, 643.1ms\n",
      "Speed: 1.0ms preprocess, 643.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051500.jpg: 384x640 1 car, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051600.jpg: 384x640 1 car, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051700.jpg: 384x640 3 cars, 649.1ms\n",
      "Speed: 1.0ms preprocess, 649.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051800.jpg: 384x640 2 cars, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_051900.jpg: 384x640 2 cars, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052000.jpg: 384x640 1 person, 2 cars, 642.0ms\n",
      "Speed: 1.0ms preprocess, 642.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052100.jpg: 384x640 2 persons, 3 cars, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052200.jpg: 384x640 2 persons, 1 car, 1 traffic light, 654.2ms\n",
      "Speed: 1.0ms preprocess, 654.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052300.jpg: 384x640 1 car, 646.0ms\n",
      "Speed: 1.0ms preprocess, 646.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052400.jpg: 384x640 1 person, 1 bus, 642.6ms\n",
      "Speed: 1.0ms preprocess, 642.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052500.jpg: 384x640 2 cars, 646.1ms\n",
      "Speed: 1.0ms preprocess, 646.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052600.jpg: 384x640 2 cars, 644.0ms\n",
      "Speed: 1.0ms preprocess, 644.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052700.jpg: 384x640 3 persons, 3 cars, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052800.jpg: 384x640 1 person, 2 cars, 1 bus, 648.1ms\n",
      "Speed: 1.0ms preprocess, 648.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_052900.jpg: 384x640 (no detections), 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053000.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053100.jpg: 384x640 2 persons, 3 cars, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053200.jpg: 384x640 3 persons, 1 car, 648.6ms\n",
      "Speed: 1.0ms preprocess, 648.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053300.jpg: 384x640 3 persons, 3 cars, 1 bus, 1 traffic light, 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053400.jpg: 384x640 2 persons, 1 car, 647.7ms\n",
      "Speed: 1.0ms preprocess, 647.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053500.jpg: 384x640 2 persons, 1 car, 648.6ms\n",
      "Speed: 1.0ms preprocess, 648.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053600.jpg: 384x640 3 persons, 1 car, 646.1ms\n",
      "Speed: 1.0ms preprocess, 646.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053700.jpg: 384x640 2 persons, 3 cars, 648.6ms\n",
      "Speed: 1.0ms preprocess, 648.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053800.jpg: 384x640 2 cars, 1 bus, 649.6ms\n",
      "Speed: 1.0ms preprocess, 649.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_053900.jpg: 384x640 1 bus, 642.0ms\n",
      "Speed: 1.0ms preprocess, 642.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054000.jpg: 384x640 1 person, 1 car, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054100.jpg: 384x640 3 persons, 2 cars, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054200.jpg: 384x640 3 persons, 2 cars, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054300.jpg: 384x640 2 cars, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054400.jpg: 384x640 2 cars, 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054500.jpg: 384x640 2 persons, 3 cars, 642.1ms\n",
      "Speed: 1.0ms preprocess, 642.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054600.jpg: 384x640 2 cars, 648.6ms\n",
      "Speed: 1.0ms preprocess, 648.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054700.jpg: 384x640 (no detections), 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054800.jpg: 384x640 1 person, 1 car, 1 bus, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_054900.jpg: 384x640 1 person, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055000.jpg: 384x640 2 persons, 1 car, 641.0ms\n",
      "Speed: 1.0ms preprocess, 641.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055100.jpg: 384x640 2 persons, 1 car, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055200.jpg: 384x640 2 persons, 1 car, 1 traffic light, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055300.jpg: 384x640 1 person, 3 cars, 1 traffic light, 685.2ms\n",
      "Speed: 1.0ms preprocess, 685.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055400.jpg: 384x640 1 person, 652.7ms\n",
      "Speed: 1.0ms preprocess, 652.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055500.jpg: 384x640 2 persons, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055600.jpg: 384x640 (no detections), 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055700.jpg: 384x640 2 persons, 3 cars, 648.1ms\n",
      "Speed: 0.0ms preprocess, 648.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055800.jpg: 384x640 3 persons, 3 cars, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_055900.jpg: 384x640 1 person, 2 cars, 643.6ms\n",
      "Speed: 1.0ms preprocess, 643.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060000.jpg: 384x640 4 cars, 649.1ms\n",
      "Speed: 1.0ms preprocess, 649.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060100.jpg: 384x640 1 person, 2 cars, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060200.jpg: 384x640 1 car, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060300.jpg: 384x640 2 cars, 1 truck, 650.1ms\n",
      "Speed: 1.0ms preprocess, 650.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060400.jpg: 384x640 1 person, 2 cars, 647.6ms\n",
      "Speed: 1.0ms preprocess, 647.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060500.jpg: 384x640 1 person, 1 car, 645.6ms\n",
      "Speed: 2.0ms preprocess, 645.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060600.jpg: 384x640 1 car, 648.1ms\n",
      "Speed: 1.0ms preprocess, 648.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060700.jpg: 384x640 3 persons, 3 cars, 646.6ms\n",
      "Speed: 1.0ms preprocess, 646.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060800.jpg: 384x640 2 persons, 646.0ms\n",
      "Speed: 1.0ms preprocess, 646.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_060900.jpg: 384x640 1 person, 2 cars, 643.1ms\n",
      "Speed: 1.0ms preprocess, 643.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061000.jpg: 384x640 3 persons, 2 cars, 643.6ms\n",
      "Speed: 1.0ms preprocess, 643.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061100.jpg: 384x640 1 person, 2 cars, 1 tv, 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061200.jpg: 384x640 2 persons, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061300.jpg: 384x640 3 persons, 1 car, 640.6ms\n",
      "Speed: 1.0ms preprocess, 640.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061400.jpg: 384x640 2 persons, 1 car, 1 train, 649.0ms\n",
      "Speed: 1.0ms preprocess, 649.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061500.jpg: 384x640 1 person, 658.6ms\n",
      "Speed: 1.0ms preprocess, 658.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061600.jpg: 384x640 4 persons, 1 car, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061700.jpg: 384x640 3 persons, 1 car, 654.6ms\n",
      "Speed: 1.0ms preprocess, 654.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061800.jpg: 384x640 1 car, 648.0ms\n",
      "Speed: 1.0ms preprocess, 648.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_061900.jpg: 384x640 1 person, 6 cars, 1 bus, 645.0ms\n",
      "Speed: 1.0ms preprocess, 645.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062000.jpg: 384x640 1 car, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062100.jpg: 384x640 2 persons, 3 cars, 1 bus, 645.0ms\n",
      "Speed: 1.0ms preprocess, 645.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062200.jpg: 384x640 5 persons, 3 cars, 1 bus, 643.6ms\n",
      "Speed: 1.0ms preprocess, 643.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062300.jpg: 384x640 3 persons, 651.6ms\n",
      "Speed: 1.0ms preprocess, 651.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062400.jpg: 384x640 1 person, 1 car, 1 truck, 650.1ms\n",
      "Speed: 1.0ms preprocess, 650.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062500.jpg: 384x640 3 persons, 1 car, 649.6ms\n",
      "Speed: 1.0ms preprocess, 649.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062600.jpg: 384x640 3 cars, 1 bus, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062700.jpg: 384x640 3 persons, 1 car, 646.1ms\n",
      "Speed: 1.0ms preprocess, 646.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062800.jpg: 384x640 1 person, 2 cars, 642.7ms\n",
      "Speed: 1.0ms preprocess, 642.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_062900.jpg: 384x640 2 persons, 1 car, 643.1ms\n",
      "Speed: 1.0ms preprocess, 643.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063000.jpg: 384x640 4 persons, 2 cars, 1 bus, 644.0ms\n",
      "Speed: 1.0ms preprocess, 644.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063100.jpg: 384x640 2 persons, 3 cars, 2 buss, 650.6ms\n",
      "Speed: 1.0ms preprocess, 650.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063200.jpg: 384x640 1 person, 1 bus, 651.6ms\n",
      "Speed: 1.0ms preprocess, 651.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063300.jpg: 384x640 3 persons, 3 cars, 1 bus, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063400.jpg: 384x640 1 person, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063500.jpg: 384x640 1 person, 2 cars, 649.1ms\n",
      "Speed: 1.0ms preprocess, 649.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063600.jpg: 384x640 2 persons, 3 cars, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063700.jpg: 384x640 3 persons, 1 car, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063800.jpg: 384x640 3 persons, 1 car, 681.1ms\n",
      "Speed: 1.0ms preprocess, 681.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_063900.jpg: 384x640 1 person, 1 car, 647.1ms\n",
      "Speed: 1.0ms preprocess, 647.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064000.jpg: 384x640 4 cars, 2 buss, 1 truck, 645.1ms\n",
      "Speed: 1.0ms preprocess, 645.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064100.jpg: 384x640 3 persons, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064200.jpg: 384x640 1 person, 2 cars, 644.0ms\n",
      "Speed: 1.0ms preprocess, 644.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064300.jpg: 384x640 2 persons, 1 car, 1 truck, 648.6ms\n",
      "Speed: 1.0ms preprocess, 648.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064400.jpg: 384x640 2 persons, 3 cars, 643.6ms\n",
      "Speed: 1.0ms preprocess, 643.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064500.jpg: 384x640 1 car, 647.1ms\n",
      "Speed: 1.0ms preprocess, 647.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064600.jpg: 384x640 3 persons, 1 car, 649.6ms\n",
      "Speed: 1.0ms preprocess, 649.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064700.jpg: 384x640 3 persons, 8 cars, 644.6ms\n",
      "Speed: 1.0ms preprocess, 644.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064800.jpg: 384x640 2 persons, 644.1ms\n",
      "Speed: 1.0ms preprocess, 644.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_064900.jpg: 384x640 2 persons, 3 cars, 1 bus, 645.6ms\n",
      "Speed: 1.0ms preprocess, 645.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065000.jpg: 384x640 3 persons, 2 cars, 1 bus, 642.0ms\n",
      "Speed: 1.0ms preprocess, 642.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065100.jpg: 384x640 3 persons, 2 cars, 643.1ms\n",
      "Speed: 1.0ms preprocess, 643.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065200.jpg: 384x640 2 persons, 1 car, 653.6ms\n",
      "Speed: 1.0ms preprocess, 653.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065300.jpg: 384x640 2 persons, 1 car, 1 bus, 1 truck, 654.7ms\n",
      "Speed: 1.0ms preprocess, 654.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065400.jpg: 384x640 3 persons, 4 cars, 2 buss, 1 truck, 647.1ms\n",
      "Speed: 1.0ms preprocess, 647.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065500.jpg: 384x640 3 persons, 1 bus, 652.6ms\n",
      "Speed: 1.0ms preprocess, 652.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065600.jpg: 384x640 3 persons, 4 cars, 1 truck, 657.4ms\n",
      "Speed: 1.0ms preprocess, 657.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065700.jpg: 384x640 1 person, 1 truck, 650.1ms\n",
      "Speed: 1.0ms preprocess, 650.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065800.jpg: 384x640 2 persons, 1 car, 657.2ms\n",
      "Speed: 1.0ms preprocess, 657.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_065900.jpg: 384x640 1 car, 1 bus, 651.9ms\n",
      "Speed: 1.0ms preprocess, 651.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070000.jpg: 384x640 4 persons, 2 cars, 1 train, 661.9ms\n",
      "Speed: 1.0ms preprocess, 661.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070100.jpg: 384x640 1 person, 6 cars, 675.6ms\n",
      "Speed: 1.0ms preprocess, 675.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070200.jpg: 384x640 3 persons, 2 cars, 1 bus, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070300.jpg: 384x640 7 cars, 2 buss, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070400.jpg: 384x640 2 persons, 673.1ms\n",
      "Speed: 1.0ms preprocess, 673.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070500.jpg: 384x640 5 persons, 1 car, 1 bus, 666.0ms\n",
      "Speed: 1.0ms preprocess, 666.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070600.jpg: 384x640 2 persons, 3 cars, 1 bus, 661.6ms\n",
      "Speed: 1.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070700.jpg: 384x640 1 car, 679.6ms\n",
      "Speed: 1.0ms preprocess, 679.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070800.jpg: 384x640 3 persons, 1 car, 690.6ms\n",
      "Speed: 1.0ms preprocess, 690.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_070900.jpg: 384x640 1 car, 661.7ms\n",
      "Speed: 1.0ms preprocess, 661.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071000.jpg: 384x640 2 persons, 5 cars, 2 buss, 661.7ms\n",
      "Speed: 1.0ms preprocess, 661.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071100.jpg: 384x640 1 person, 1 car, 659.1ms\n",
      "Speed: 1.0ms preprocess, 659.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071200.jpg: 384x640 3 persons, 2 cars, 1 bus, 661.1ms\n",
      "Speed: 1.0ms preprocess, 661.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071300.jpg: 384x640 1 person, 5 cars, 2 buss, 658.1ms\n",
      "Speed: 1.0ms preprocess, 658.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071400.jpg: 384x640 1 car, 661.4ms\n",
      "Speed: 1.0ms preprocess, 661.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071500.jpg: 384x640 3 persons, 3 cars, 1 bus, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071600.jpg: 384x640 2 cars, 662.8ms\n",
      "Speed: 1.0ms preprocess, 662.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071700.jpg: 384x640 4 persons, 4 cars, 1 bus, 1 truck, 677.1ms\n",
      "Speed: 1.0ms preprocess, 677.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071800.jpg: 384x640 1 person, 2 cars, 658.4ms\n",
      "Speed: 1.0ms preprocess, 658.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_071900.jpg: 384x640 3 persons, 2 cars, 664.1ms\n",
      "Speed: 1.5ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072000.jpg: 384x640 3 persons, 2 cars, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072100.jpg: 384x640 2 cars, 1 bus, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072200.jpg: 384x640 2 persons, 1 car, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072300.jpg: 384x640 1 person, 1 car, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072400.jpg: 384x640 3 persons, 1 car, 1 bus, 658.4ms\n",
      "Speed: 1.0ms preprocess, 658.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072500.jpg: 384x640 2 persons, 1 car, 2 buss, 1 truck, 655.5ms\n",
      "Speed: 1.0ms preprocess, 655.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072600.jpg: 384x640 3 persons, 665.6ms\n",
      "Speed: 0.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072700.jpg: 384x640 1 car, 1 bus, 668.3ms\n",
      "Speed: 2.0ms preprocess, 668.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072800.jpg: 384x640 1 person, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_072900.jpg: 384x640 2 cars, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073000.jpg: 384x640 1 person, 1 car, 678.1ms\n",
      "Speed: 1.0ms preprocess, 678.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073100.jpg: 384x640 1 person, 3 cars, 2 buss, 659.5ms\n",
      "Speed: 1.0ms preprocess, 659.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073200.jpg: 384x640 2 persons, 2 cars, 1 bus, 657.9ms\n",
      "Speed: 1.0ms preprocess, 657.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073300.jpg: 384x640 2 persons, 1 car, 656.6ms\n",
      "Speed: 1.0ms preprocess, 656.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073400.jpg: 384x640 3 persons, 2 cars, 1 bus, 653.8ms\n",
      "Speed: 1.0ms preprocess, 653.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073500.jpg: 384x640 2 cars, 1 bus, 660.1ms\n",
      "Speed: 1.0ms preprocess, 660.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073600.jpg: 384x640 3 persons, 2 cars, 1 bus, 658.3ms\n",
      "Speed: 1.0ms preprocess, 658.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073700.jpg: 384x640 1 person, 1 truck, 652.7ms\n",
      "Speed: 1.0ms preprocess, 652.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073800.jpg: 384x640 4 persons, 1 car, 1 bus, 1 truck, 658.5ms\n",
      "Speed: 1.0ms preprocess, 658.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_073900.jpg: 384x640 1 person, 1 car, 1 bus, 658.2ms\n",
      "Speed: 1.0ms preprocess, 658.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074000.jpg: 384x640 1 car, 2 trucks, 652.3ms\n",
      "Speed: 1.0ms preprocess, 652.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074100.jpg: 384x640 2 persons, 2 cars, 1 truck, 658.6ms\n",
      "Speed: 1.0ms preprocess, 658.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074200.jpg: 384x640 2 persons, 660.7ms\n",
      "Speed: 1.0ms preprocess, 660.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074300.jpg: 384x640 4 cars, 1 bus, 1 truck, 655.1ms\n",
      "Speed: 1.0ms preprocess, 655.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074400.jpg: 384x640 1 person, 1 car, 656.3ms\n",
      "Speed: 1.0ms preprocess, 656.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074500.jpg: 384x640 2 persons, 4 cars, 1 bus, 654.9ms\n",
      "Speed: 1.0ms preprocess, 654.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074600.jpg: 384x640 2 buss, 654.7ms\n",
      "Speed: 1.0ms preprocess, 654.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074700.jpg: 384x640 1 person, 1 car, 654.4ms\n",
      "Speed: 1.0ms preprocess, 654.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074800.jpg: 384x640 4 cars, 2 buss, 657.2ms\n",
      "Speed: 1.0ms preprocess, 657.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_074900.jpg: 384x640 2 cars, 4 buss, 654.7ms\n",
      "Speed: 1.0ms preprocess, 654.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075000.jpg: 384x640 3 cars, 2 buss, 660.6ms\n",
      "Speed: 1.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075100.jpg: 384x640 1 truck, 659.3ms\n",
      "Speed: 1.0ms preprocess, 659.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075200.jpg: 384x640 2 cars, 656.1ms\n",
      "Speed: 1.0ms preprocess, 656.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075300.jpg: 384x640 1 car, 658.6ms\n",
      "Speed: 1.0ms preprocess, 658.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075400.jpg: 384x640 1 person, 1 car, 2 buss, 652.6ms\n",
      "Speed: 1.0ms preprocess, 652.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075500.jpg: 384x640 5 cars, 1 bus, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075600.jpg: 384x640 1 person, 1 car, 673.2ms\n",
      "Speed: 1.0ms preprocess, 673.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075700.jpg: 384x640 2 cars, 681.7ms\n",
      "Speed: 1.0ms preprocess, 681.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075800.jpg: 384x640 (no detections), 675.1ms\n",
      "Speed: 1.0ms preprocess, 675.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_075900.jpg: 384x640 1 person, 5 cars, 3 buss, 689.5ms\n",
      "Speed: 1.0ms preprocess, 689.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080000.jpg: 384x640 1 person, 3 cars, 3 buss, 686.1ms\n",
      "Speed: 1.0ms preprocess, 686.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080100.jpg: 384x640 1 car, 672.1ms\n",
      "Speed: 1.0ms preprocess, 672.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080200.jpg: 384x640 4 persons, 712.7ms\n",
      "Speed: 1.0ms preprocess, 712.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080300.jpg: 384x640 (no detections), 681.3ms\n",
      "Speed: 1.0ms preprocess, 681.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080400.jpg: 384x640 3 persons, 1 car, 669.7ms\n",
      "Speed: 1.0ms preprocess, 669.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080500.jpg: 384x640 1 car, 674.8ms\n",
      "Speed: 1.0ms preprocess, 674.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080600.jpg: 384x640 4 persons, 1 car, 1 bus, 668.4ms\n",
      "Speed: 1.0ms preprocess, 668.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080700.jpg: 384x640 2 cars, 3 buss, 1 truck, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080800.jpg: 384x640 1 car, 1 bus, 670.6ms\n",
      "Speed: 0.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_080900.jpg: 384x640 3 persons, 2 cars, 1 bus, 715.2ms\n",
      "Speed: 1.0ms preprocess, 715.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081000.jpg: 384x640 1 bus, 695.2ms\n",
      "Speed: 1.0ms preprocess, 695.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081100.jpg: 384x640 2 persons, 3 cars, 2 trucks, 656.2ms\n",
      "Speed: 1.0ms preprocess, 656.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081200.jpg: 384x640 2 persons, 1 bus, 659.2ms\n",
      "Speed: 1.0ms preprocess, 659.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081300.jpg: 384x640 2 persons, 1 car, 1 bus, 654.7ms\n",
      "Speed: 1.0ms preprocess, 654.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081400.jpg: 384x640 2 cars, 3 buss, 647.8ms\n",
      "Speed: 1.0ms preprocess, 647.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081500.jpg: 384x640 1 person, 1 car, 2 trucks, 654.4ms\n",
      "Speed: 1.0ms preprocess, 654.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081600.jpg: 384x640 4 cars, 2 trucks, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081700.jpg: 384x640 1 car, 1 truck, 654.8ms\n",
      "Speed: 1.0ms preprocess, 654.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081800.jpg: 384x640 7 cars, 1 truck, 652.8ms\n",
      "Speed: 1.0ms preprocess, 652.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_081900.jpg: 384x640 1 bus, 1 truck, 654.2ms\n",
      "Speed: 1.0ms preprocess, 654.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082000.jpg: 384x640 3 persons, 6 cars, 1 truck, 656.1ms\n",
      "Speed: 1.0ms preprocess, 656.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082100.jpg: 384x640 3 cars, 1 bus, 655.5ms\n",
      "Speed: 1.0ms preprocess, 655.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082200.jpg: 384x640 1 person, 2 cars, 656.5ms\n",
      "Speed: 1.0ms preprocess, 656.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082300.jpg: 384x640 1 person, 2 cars, 659.0ms\n",
      "Speed: 1.0ms preprocess, 659.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082400.jpg: 384x640 2 cars, 1 bus, 684.0ms\n",
      "Speed: 1.0ms preprocess, 684.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082500.jpg: 384x640 2 persons, 3 cars, 2 buss, 1 truck, 674.0ms\n",
      "Speed: 1.0ms preprocess, 674.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082600.jpg: 384x640 1 car, 657.0ms\n",
      "Speed: 1.0ms preprocess, 657.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082700.jpg: 384x640 5 cars, 1 motorcycle, 654.5ms\n",
      "Speed: 2.0ms preprocess, 654.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082800.jpg: 384x640 1 car, 1 bus, 658.5ms\n",
      "Speed: 1.0ms preprocess, 658.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_082900.jpg: 384x640 2 cars, 652.6ms\n",
      "Speed: 1.0ms preprocess, 652.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083000.jpg: 384x640 1 person, 3 cars, 661.3ms\n",
      "Speed: 1.0ms preprocess, 661.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083100.jpg: 384x640 1 car, 1 bus, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083200.jpg: 384x640 2 persons, 4 cars, 2 buss, 680.6ms\n",
      "Speed: 1.0ms preprocess, 680.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083300.jpg: 384x640 1 person, 2 buss, 667.5ms\n",
      "Speed: 1.0ms preprocess, 667.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083400.jpg: 384x640 2 persons, 1 car, 2 buss, 1 truck, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083500.jpg: 384x640 2 buss, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083600.jpg: 384x640 4 cars, 660.5ms\n",
      "Speed: 1.0ms preprocess, 660.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083700.jpg: 384x640 3 cars, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083800.jpg: 384x640 3 cars, 1 bus, 708.6ms\n",
      "Speed: 1.0ms preprocess, 708.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_083900.jpg: 384x640 2 persons, 5 cars, 4 buss, 666.5ms\n",
      "Speed: 1.0ms preprocess, 666.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084000.jpg: 384x640 1 car, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084100.jpg: 384x640 5 cars, 3 buss, 661.0ms\n",
      "Speed: 1.0ms preprocess, 661.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084200.jpg: 384x640 3 cars, 2 buss, 660.0ms\n",
      "Speed: 1.0ms preprocess, 660.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084300.jpg: 384x640 4 cars, 1 bus, 674.5ms\n",
      "Speed: 1.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084400.jpg: 384x640 1 person, 3 cars, 667.5ms\n",
      "Speed: 2.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084500.jpg: 384x640 1 person, 3 cars, 665.5ms\n",
      "Speed: 1.0ms preprocess, 665.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084600.jpg: 384x640 3 cars, 1 bus, 687.1ms\n",
      "Speed: 0.0ms preprocess, 687.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084700.jpg: 384x640 3 cars, 2 buss, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084800.jpg: 384x640 4 cars, 3 buss, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_084900.jpg: 384x640 1 person, 2 cars, 2 buss, 1 truck, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085000.jpg: 384x640 1 person, 666.5ms\n",
      "Speed: 0.0ms preprocess, 666.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085100.jpg: 384x640 1 person, 2 cars, 1 bus, 686.6ms\n",
      "Speed: 1.0ms preprocess, 686.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085200.jpg: 384x640 1 person, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085300.jpg: 384x640 1 person, 4 cars, 3 buss, 691.6ms\n",
      "Speed: 1.0ms preprocess, 691.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085400.jpg: 384x640 3 cars, 1 bus, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085500.jpg: 384x640 2 cars, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085600.jpg: 384x640 1 person, 1 car, 672.9ms\n",
      "Speed: 1.0ms preprocess, 672.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085700.jpg: 384x640 1 car, 2 buss, 678.1ms\n",
      "Speed: 1.0ms preprocess, 678.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085800.jpg: 384x640 2 buss, 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_085900.jpg: 384x640 1 car, 673.3ms\n",
      "Speed: 1.0ms preprocess, 673.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090000.jpg: 384x640 6 cars, 3 buss, 676.3ms\n",
      "Speed: 1.0ms preprocess, 676.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090100.jpg: 384x640 2 cars, 1 bus, 1 truck, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090200.jpg: 384x640 1 car, 2 buss, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090300.jpg: 384x640 1 person, 3 cars, 3 buss, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090400.jpg: 384x640 (no detections), 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090500.jpg: 384x640 3 persons, 4 cars, 1 truck, 672.4ms\n",
      "Speed: 1.0ms preprocess, 672.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090600.jpg: 384x640 2 cars, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090700.jpg: 384x640 5 cars, 1 bus, 671.0ms\n",
      "Speed: 1.0ms preprocess, 671.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090800.jpg: 384x640 4 cars, 1 bus, 658.1ms\n",
      "Speed: 1.0ms preprocess, 658.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_090900.jpg: 384x640 3 cars, 2 buss, 671.1ms\n",
      "Speed: 1.0ms preprocess, 671.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091000.jpg: 384x640 3 cars, 1 bus, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091100.jpg: 384x640 1 bus, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091200.jpg: 384x640 1 person, 2 cars, 2 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091300.jpg: 384x640 1 car, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091400.jpg: 384x640 1 person, 5 cars, 2 buss, 1 truck, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091500.jpg: 384x640 7 cars, 1 bus, 658.1ms\n",
      "Speed: 1.0ms preprocess, 658.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091600.jpg: 384x640 4 cars, 668.3ms\n",
      "Speed: 1.0ms preprocess, 668.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091700.jpg: 384x640 5 cars, 751.0ms\n",
      "Speed: 1.0ms preprocess, 751.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091800.jpg: 384x640 1 car, 1 bus, 678.6ms\n",
      "Speed: 2.0ms preprocess, 678.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_091900.jpg: 384x640 1 person, 2 cars, 1 bus, 699.5ms\n",
      "Speed: 1.0ms preprocess, 699.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092000.jpg: 384x640 1 bus, 706.1ms\n",
      "Speed: 1.0ms preprocess, 706.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092100.jpg: 384x640 4 cars, 1 bus, 693.6ms\n",
      "Speed: 1.0ms preprocess, 693.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092200.jpg: 384x640 1 person, 1 car, 1 bus, 681.6ms\n",
      "Speed: 2.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092300.jpg: 384x640 1 car, 704.1ms\n",
      "Speed: 2.0ms preprocess, 704.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092400.jpg: 384x640 2 cars, 678.1ms\n",
      "Speed: 1.0ms preprocess, 678.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092500.jpg: 384x640 1 bus, 679.4ms\n",
      "Speed: 1.0ms preprocess, 679.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092600.jpg: 384x640 3 cars, 3 buss, 684.6ms\n",
      "Speed: 2.0ms preprocess, 684.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092700.jpg: 384x640 (no detections), 675.6ms\n",
      "Speed: 2.0ms preprocess, 675.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092800.jpg: 384x640 6 cars, 2 buss, 667.2ms\n",
      "Speed: 1.0ms preprocess, 667.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_092900.jpg: 384x640 1 car, 2 buss, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093000.jpg: 384x640 1 person, 1 car, 667.1ms\n",
      "Speed: 1.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093100.jpg: 384x640 4 cars, 666.6ms\n",
      "Speed: 2.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093200.jpg: 384x640 3 cars, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093300.jpg: 384x640 8 cars, 2 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093400.jpg: 384x640 1 car, 683.6ms\n",
      "Speed: 1.0ms preprocess, 683.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093500.jpg: 384x640 9 cars, 666.4ms\n",
      "Speed: 1.0ms preprocess, 666.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093600.jpg: 384x640 3 cars, 2 buss, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093700.jpg: 384x640 2 persons, 5 cars, 680.6ms\n",
      "Speed: 2.0ms preprocess, 680.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093800.jpg: 384x640 5 cars, 1 bus, 668.6ms\n",
      "Speed: 2.0ms preprocess, 668.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_093900.jpg: 384x640 1 car, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094000.jpg: 384x640 6 cars, 1 bus, 666.8ms\n",
      "Speed: 1.0ms preprocess, 666.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094100.jpg: 384x640 1 car, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094200.jpg: 384x640 2 cars, 5 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094300.jpg: 384x640 4 cars, 1 bus, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094400.jpg: 384x640 2 cars, 3 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094500.jpg: 384x640 6 cars, 2 buss, 668.2ms\n",
      "Speed: 1.0ms preprocess, 668.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094600.jpg: 384x640 (no detections), 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094700.jpg: 384x640 5 cars, 2 buss, 671.3ms\n",
      "Speed: 2.0ms preprocess, 671.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094800.jpg: 384x640 2 cars, 2 buss, 663.0ms\n",
      "Speed: 1.0ms preprocess, 663.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_094900.jpg: 384x640 7 cars, 1 bus, 670.1ms\n",
      "Speed: 1.5ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095000.jpg: 384x640 2 buss, 670.9ms\n",
      "Speed: 1.0ms preprocess, 670.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095100.jpg: 384x640 1 car, 670.1ms\n",
      "Speed: 2.0ms preprocess, 670.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095200.jpg: 384x640 3 cars, 663.5ms\n",
      "Speed: 2.0ms preprocess, 663.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095300.jpg: 384x640 2 cars, 670.6ms\n",
      "Speed: 2.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095400.jpg: 384x640 1 person, 9 cars, 1 bus, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095500.jpg: 384x640 1 car, 1 bus, 669.7ms\n",
      "Speed: 1.0ms preprocess, 669.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095600.jpg: 384x640 7 cars, 1 bus, 667.1ms\n",
      "Speed: 1.0ms preprocess, 667.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095700.jpg: 384x640 3 cars, 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095800.jpg: 384x640 3 cars, 2 buss, 674.6ms\n",
      "Speed: 2.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_095900.jpg: 384x640 2 cars, 3 buss, 671.7ms\n",
      "Speed: 2.0ms preprocess, 671.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100000.jpg: 384x640 2 cars, 670.7ms\n",
      "Speed: 1.0ms preprocess, 670.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100100.jpg: 384x640 5 cars, 1 bus, 664.5ms\n",
      "Speed: 2.0ms preprocess, 664.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100200.jpg: 384x640 1 bus, 674.3ms\n",
      "Speed: 1.0ms preprocess, 674.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100300.jpg: 384x640 1 person, 7 cars, 2 buss, 672.7ms\n",
      "Speed: 2.0ms preprocess, 672.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100400.jpg: 384x640 3 cars, 3 buss, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100500.jpg: 384x640 2 cars, 1 bus, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100600.jpg: 384x640 2 cars, 4 buss, 689.6ms\n",
      "Speed: 1.0ms preprocess, 689.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100700.jpg: 384x640 (no detections), 669.2ms\n",
      "Speed: 2.0ms preprocess, 669.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100800.jpg: 384x640 6 cars, 663.0ms\n",
      "Speed: 1.0ms preprocess, 663.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_100900.jpg: 384x640 (no detections), 672.3ms\n",
      "Speed: 1.0ms preprocess, 672.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101000.jpg: 384x640 6 cars, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101100.jpg: 384x640 6 cars, 1 bus, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101200.jpg: 384x640 3 cars, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101300.jpg: 384x640 2 cars, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101400.jpg: 384x640 2 cars, 3 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101500.jpg: 384x640 3 cars, 4 buss, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101600.jpg: 384x640 1 car, 2 buss, 667.3ms\n",
      "Speed: 2.0ms preprocess, 667.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101700.jpg: 384x640 5 cars, 2 buss, 668.1ms\n",
      "Speed: 1.5ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101800.jpg: 384x640 1 car, 1 bus, 675.6ms\n",
      "Speed: 2.0ms preprocess, 675.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_101900.jpg: 384x640 4 cars, 664.8ms\n",
      "Speed: 1.0ms preprocess, 664.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102000.jpg: 384x640 8 cars, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102100.jpg: 384x640 1 car, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102200.jpg: 384x640 1 person, 2 cars, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102300.jpg: 384x640 1 car, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102400.jpg: 384x640 6 cars, 1 bus, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102500.jpg: 384x640 2 cars, 3 buss, 667.2ms\n",
      "Speed: 1.0ms preprocess, 667.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102600.jpg: 384x640 1 car, 1 bus, 672.1ms\n",
      "Speed: 1.0ms preprocess, 672.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102700.jpg: 384x640 3 cars, 1 bus, 674.7ms\n",
      "Speed: 1.0ms preprocess, 674.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102800.jpg: 384x640 2 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_102900.jpg: 384x640 4 cars, 3 buss, 668.5ms\n",
      "Speed: 2.0ms preprocess, 668.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103000.jpg: 384x640 1 car, 2 buss, 671.2ms\n",
      "Speed: 1.0ms preprocess, 671.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103100.jpg: 384x640 5 cars, 3 buss, 662.0ms\n",
      "Speed: 1.0ms preprocess, 662.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103200.jpg: 384x640 3 cars, 1 bus, 665.6ms\n",
      "Speed: 2.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103300.jpg: 384x640 2 cars, 1 bus, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103400.jpg: 384x640 5 cars, 1 truck, 664.3ms\n",
      "Speed: 2.0ms preprocess, 664.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103500.jpg: 384x640 2 cars, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103600.jpg: 384x640 6 cars, 2 buss, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103700.jpg: 384x640 (no detections), 660.8ms\n",
      "Speed: 1.0ms preprocess, 660.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103800.jpg: 384x640 9 cars, 1 bus, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_103900.jpg: 384x640 6 cars, 2 buss, 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104000.jpg: 384x640 1 car, 664.3ms\n",
      "Speed: 1.0ms preprocess, 664.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104100.jpg: 384x640 3 cars, 1 bus, 683.6ms\n",
      "Speed: 1.0ms preprocess, 683.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104200.jpg: 384x640 1 car, 663.7ms\n",
      "Speed: 2.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104300.jpg: 384x640 3 cars, 662.8ms\n",
      "Speed: 2.0ms preprocess, 662.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104400.jpg: 384x640 1 bus, 670.7ms\n",
      "Speed: 2.0ms preprocess, 670.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104500.jpg: 384x640 9 cars, 2 buss, 668.9ms\n",
      "Speed: 1.0ms preprocess, 668.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104600.jpg: 384x640 1 car, 4 buss, 663.7ms\n",
      "Speed: 1.0ms preprocess, 663.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104700.jpg: 384x640 1 car, 666.8ms\n",
      "Speed: 1.0ms preprocess, 666.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104800.jpg: 384x640 2 cars, 1 bus, 670.4ms\n",
      "Speed: 1.0ms preprocess, 670.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_104900.jpg: 384x640 1 car, 663.8ms\n",
      "Speed: 2.0ms preprocess, 663.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105000.jpg: 384x640 8 cars, 1 bus, 1 truck, 665.0ms\n",
      "Speed: 1.0ms preprocess, 665.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105100.jpg: 384x640 1 person, 2 buss, 666.8ms\n",
      "Speed: 1.0ms preprocess, 666.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105200.jpg: 384x640 7 cars, 1 bus, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105300.jpg: 384x640 2 cars, 663.9ms\n",
      "Speed: 2.0ms preprocess, 663.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105400.jpg: 384x640 2 cars, 1 bus, 664.1ms\n",
      "Speed: 2.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105500.jpg: 384x640 8 cars, 1 bus, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105600.jpg: 384x640 2 cars, 1 bus, 666.1ms\n",
      "Speed: 1.2ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105700.jpg: 384x640 8 cars, 3 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105800.jpg: 384x640 5 cars, 3 buss, 668.8ms\n",
      "Speed: 1.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_105900.jpg: 384x640 9 cars, 3 buss, 661.6ms\n",
      "Speed: 1.0ms preprocess, 661.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110000.jpg: 384x640 5 cars, 4 buss, 666.5ms\n",
      "Speed: 1.0ms preprocess, 666.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110100.jpg: 384x640 2 cars, 668.8ms\n",
      "Speed: 1.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110200.jpg: 384x640 5 cars, 1 bus, 667.1ms\n",
      "Speed: 2.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110300.jpg: 384x640 2 cars, 662.1ms\n",
      "Speed: 2.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110400.jpg: 384x640 9 cars, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110500.jpg: 384x640 1 car, 1 bus, 666.9ms\n",
      "Speed: 1.0ms preprocess, 666.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110600.jpg: 384x640 6 cars, 2 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110700.jpg: 384x640 3 cars, 3 buss, 672.8ms\n",
      "Speed: 1.0ms preprocess, 672.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110800.jpg: 384x640 3 cars, 1 bus, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_110900.jpg: 384x640 5 cars, 1 bus, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111000.jpg: 384x640 2 cars, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111100.jpg: 384x640 7 cars, 1 bus, 661.1ms\n",
      "Speed: 2.0ms preprocess, 661.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111200.jpg: 384x640 2 cars, 1 bus, 1 tv, 668.8ms\n",
      "Speed: 1.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111300.jpg: 384x640 11 cars, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111400.jpg: 384x640 4 cars, 1 bus, 697.6ms\n",
      "Speed: 2.0ms preprocess, 697.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111500.jpg: 384x640 3 cars, 670.1ms\n",
      "Speed: 2.0ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111600.jpg: 384x640 1 car, 2 buss, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111700.jpg: 384x640 1 car, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111800.jpg: 384x640 7 cars, 669.2ms\n",
      "Speed: 1.0ms preprocess, 669.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_111900.jpg: 384x640 1 bus, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112000.jpg: 384x640 7 cars, 2 motorcycles, 2 buss, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112100.jpg: 384x640 4 cars, 1 bus, 672.0ms\n",
      "Speed: 1.0ms preprocess, 672.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112200.jpg: 384x640 2 cars, 1 bus, 668.0ms\n",
      "Speed: 2.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112300.jpg: 384x640 7 cars, 3 buss, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112400.jpg: 384x640 1 car, 1 bus, 668.5ms\n",
      "Speed: 1.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112500.jpg: 384x640 5 cars, 1 bus, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112600.jpg: 384x640 3 cars, 1 tv, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112700.jpg: 384x640 8 cars, 1 bus, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112800.jpg: 384x640 5 cars, 3 buss, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_112900.jpg: 384x640 1 tv, 665.0ms\n",
      "Speed: 2.0ms preprocess, 665.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113000.jpg: 384x640 6 cars, 1 bus, 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113100.jpg: 384x640 1 car, 1 bus, 669.0ms\n",
      "Speed: 1.0ms preprocess, 669.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113200.jpg: 384x640 10 cars, 1 motorcycle, 2 buss, 1 truck, 1 tv, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113300.jpg: 384x640 4 cars, 666.5ms\n",
      "Speed: 2.0ms preprocess, 666.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113400.jpg: 384x640 10 cars, 2 buss, 668.5ms\n",
      "Speed: 2.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113500.jpg: 384x640 6 cars, 667.5ms\n",
      "Speed: 2.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113600.jpg: 384x640 3 cars, 2 buss, 668.5ms\n",
      "Speed: 1.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113700.jpg: 384x640 5 cars, 2 buss, 667.5ms\n",
      "Speed: 2.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113800.jpg: 384x640 2 cars, 669.5ms\n",
      "Speed: 2.0ms preprocess, 669.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_113900.jpg: 384x640 6 cars, 668.0ms\n",
      "Speed: 2.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114000.jpg: 384x640 2 cars, 673.0ms\n",
      "Speed: 2.0ms preprocess, 673.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114100.jpg: 384x640 12 cars, 2 buss, 668.0ms\n",
      "Speed: 2.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114200.jpg: 384x640 5 cars, 1 bus, 672.5ms\n",
      "Speed: 2.0ms preprocess, 672.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114300.jpg: 384x640 2 cars, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114400.jpg: 384x640 7 cars, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114500.jpg: 384x640 1 bus, 1 tv, 668.5ms\n",
      "Speed: 1.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114600.jpg: 384x640 1 person, 6 cars, 1 bus, 666.5ms\n",
      "Speed: 1.0ms preprocess, 666.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114700.jpg: 384x640 3 cars, 2 buss, 668.5ms\n",
      "Speed: 2.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114800.jpg: 384x640 8 cars, 4 buss, 679.5ms\n",
      "Speed: 1.0ms preprocess, 679.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_114900.jpg: 384x640 5 cars, 2 buss, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115000.jpg: 384x640 5 cars, 667.5ms\n",
      "Speed: 1.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115100.jpg: 384x640 5 cars, 1 bus, 670.0ms\n",
      "Speed: 1.0ms preprocess, 670.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115200.jpg: 384x640 (no detections), 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115300.jpg: 384x640 7 cars, 2 buss, 668.0ms\n",
      "Speed: 1.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115400.jpg: 384x640 1 car, 664.5ms\n",
      "Speed: 1.0ms preprocess, 664.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115500.jpg: 384x640 9 cars, 3 buss, 1 truck, 674.5ms\n",
      "Speed: 2.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115600.jpg: 384x640 6 cars, 5 buss, 668.5ms\n",
      "Speed: 2.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115700.jpg: 384x640 5 cars, 2 buss, 665.5ms\n",
      "Speed: 2.0ms preprocess, 665.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115800.jpg: 384x640 12 cars, 1 bus, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_115900.jpg: 384x640 1 bus, 1 tv, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120000.jpg: 384x640 1 car, 1 bus, 668.5ms\n",
      "Speed: 1.0ms preprocess, 668.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120100.jpg: 384x640 10 cars, 2 buss, 1 tv, 668.0ms\n",
      "Speed: 2.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120200.jpg: 384x640 7 cars, 1 motorcycle, 1 bus, 672.0ms\n",
      "Speed: 1.0ms preprocess, 672.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120300.jpg: 384x640 1 car, 670.0ms\n",
      "Speed: 1.0ms preprocess, 670.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120400.jpg: 384x640 9 cars, 1 bus, 666.0ms\n",
      "Speed: 1.5ms preprocess, 666.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120500.jpg: 384x640 2 cars, 1 bus, 671.5ms\n",
      "Speed: 1.0ms preprocess, 671.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120600.jpg: 384x640 6 cars, 2 buss, 667.5ms\n",
      "Speed: 1.0ms preprocess, 667.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120700.jpg: 384x640 1 car, 674.5ms\n",
      "Speed: 1.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120800.jpg: 384x640 7 cars, 2 buss, 671.1ms\n",
      "Speed: 1.0ms preprocess, 671.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_120900.jpg: 384x640 5 cars, 1 bus, 672.6ms\n",
      "Speed: 2.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121000.jpg: 384x640 2 cars, 1 bus, 670.5ms\n",
      "Speed: 2.0ms preprocess, 670.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121100.jpg: 384x640 3 cars, 1 bus, 1 truck, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121200.jpg: 384x640 3 cars, 670.5ms\n",
      "Speed: 1.0ms preprocess, 670.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121300.jpg: 384x640 5 cars, 1 bus, 668.0ms\n",
      "Speed: 1.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121400.jpg: 384x640 1 bus, 668.0ms\n",
      "Speed: 1.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121500.jpg: 384x640 5 cars, 1 bus, 1 truck, 671.5ms\n",
      "Speed: 1.0ms preprocess, 671.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121600.jpg: 384x640 2 cars, 1 tv, 672.5ms\n",
      "Speed: 2.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121700.jpg: 384x640 4 cars, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121800.jpg: 384x640 6 cars, 1 bus, 667.5ms\n",
      "Speed: 1.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_121900.jpg: 384x640 1 car, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122000.jpg: 384x640 6 cars, 1 bus, 1 tv, 665.5ms\n",
      "Speed: 1.0ms preprocess, 665.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122100.jpg: 384x640 1 tv, 672.5ms\n",
      "Speed: 2.0ms preprocess, 672.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122200.jpg: 384x640 9 cars, 3 buss, 1 tv, 669.5ms\n",
      "Speed: 2.0ms preprocess, 669.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122300.jpg: 384x640 4 cars, 1 bus, 672.0ms\n",
      "Speed: 1.0ms preprocess, 672.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122400.jpg: 384x640 3 cars, 2 buss, 670.0ms\n",
      "Speed: 1.0ms preprocess, 670.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122500.jpg: 384x640 10 cars, 2 buss, 671.0ms\n",
      "Speed: 1.0ms preprocess, 671.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122600.jpg: 384x640 2 cars, 1 bus, 1 tv, 671.0ms\n",
      "Speed: 1.5ms preprocess, 671.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122700.jpg: 384x640 3 cars, 2 buss, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122800.jpg: 384x640 4 cars, 1 bus, 664.3ms\n",
      "Speed: 2.0ms preprocess, 664.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_122900.jpg: 384x640 12 cars, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123000.jpg: 384x640 5 cars, 1 bus, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123100.jpg: 384x640 3 cars, 673.5ms\n",
      "Speed: 1.0ms preprocess, 673.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123200.jpg: 384x640 5 cars, 671.2ms\n",
      "Speed: 1.0ms preprocess, 671.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123300.jpg: 384x640 (no detections), 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123400.jpg: 384x640 8 cars, 1 bus, 701.7ms\n",
      "Speed: 1.0ms preprocess, 701.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123500.jpg: 384x640 1 car, 2 buss, 671.7ms\n",
      "Speed: 1.0ms preprocess, 671.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123600.jpg: 384x640 7 cars, 4 buss, 668.3ms\n",
      "Speed: 1.0ms preprocess, 668.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123700.jpg: 384x640 6 cars, 2 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123800.jpg: 384x640 4 cars, 1 bus, 1 truck, 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_123900.jpg: 384x640 5 cars, 1 tv, 665.0ms\n",
      "Speed: 1.0ms preprocess, 665.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124000.jpg: 384x640 3 cars, 675.6ms\n",
      "Speed: 1.0ms preprocess, 675.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124100.jpg: 384x640 8 cars, 1 truck, 667.4ms\n",
      "Speed: 1.0ms preprocess, 667.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124200.jpg: 384x640 1 car, 1 tv, 663.6ms\n",
      "Speed: 2.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124300.jpg: 384x640 10 cars, 666.6ms\n",
      "Speed: 2.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124400.jpg: 384x640 8 cars, 1 bus, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124500.jpg: 384x640 5 cars, 1 bus, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124600.jpg: 384x640 5 cars, 1 bus, 665.0ms\n",
      "Speed: 2.0ms preprocess, 665.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124700.jpg: 384x640 1 train, 664.1ms\n",
      "Speed: 1.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124800.jpg: 384x640 4 cars, 661.7ms\n",
      "Speed: 2.0ms preprocess, 661.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_124900.jpg: 384x640 3 cars, 1 bus, 692.5ms\n",
      "Speed: 1.0ms preprocess, 692.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125000.jpg: 384x640 11 cars, 2 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125100.jpg: 384x640 5 cars, 1 bus, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125200.jpg: 384x640 4 cars, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125300.jpg: 384x640 5 cars, 663.7ms\n",
      "Speed: 1.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125400.jpg: 384x640 1 car, 1 bus, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125500.jpg: 384x640 6 cars, 4 buss, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125600.jpg: 384x640 2 cars, 1 bus, 1 tv, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125700.jpg: 384x640 10 cars, 1 bus, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125800.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_125900.jpg: 384x640 4 cars, 1 bus, 1 tv, 663.2ms\n",
      "Speed: 2.0ms preprocess, 663.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130000.jpg: 384x640 5 cars, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130100.jpg: 384x640 1 car, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130200.jpg: 384x640 1 person, 8 cars, 1 bus, 1 tv, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130300.jpg: 384x640 2 cars, 665.8ms\n",
      "Speed: 1.0ms preprocess, 665.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130400.jpg: 384x640 1 person, 10 cars, 2 buss, 1 tv, 663.2ms\n",
      "Speed: 1.0ms preprocess, 663.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130500.jpg: 384x640 3 cars, 2 buss, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130600.jpg: 384x640 3 cars, 667.4ms\n",
      "Speed: 1.0ms preprocess, 667.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130700.jpg: 384x640 5 cars, 1 bus, 661.6ms\n",
      "Speed: 2.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130800.jpg: 384x640 1 car, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_130900.jpg: 384x640 12 cars, 668.2ms\n",
      "Speed: 2.0ms preprocess, 668.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131000.jpg: 384x640 2 buss, 667.0ms\n",
      "Speed: 1.0ms preprocess, 667.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131100.jpg: 384x640 9 cars, 667.0ms\n",
      "Speed: 2.0ms preprocess, 667.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131200.jpg: 384x640 6 cars, 3 buss, 1 tv, 663.6ms\n",
      "Speed: 2.0ms preprocess, 663.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131300.jpg: 384x640 2 buss, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131400.jpg: 384x640 1 person, 3 cars, 2 buss, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131500.jpg: 384x640 4 buss, 672.2ms\n",
      "Speed: 1.0ms preprocess, 672.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131600.jpg: 384x640 5 cars, 4 buss, 1 tv, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131700.jpg: 384x640 1 car, 1 bus, 662.1ms\n",
      "Speed: 2.0ms preprocess, 662.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131800.jpg: 384x640 7 cars, 1 motorcycle, 1 bus, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_131900.jpg: 384x640 6 cars, 1 bus, 660.6ms\n",
      "Speed: 2.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132000.jpg: 384x640 2 cars, 2 buss, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132100.jpg: 384x640 1 person, 6 cars, 1 bus, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132200.jpg: 384x640 3 cars, 1 bus, 1 tv, 663.9ms\n",
      "Speed: 2.0ms preprocess, 663.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132300.jpg: 384x640 10 cars, 663.3ms\n",
      "Speed: 1.0ms preprocess, 663.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132400.jpg: 384x640 3 cars, 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132500.jpg: 384x640 7 cars, 3 buss, 675.1ms\n",
      "Speed: 1.0ms preprocess, 675.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132600.jpg: 384x640 10 cars, 2 buss, 1 tv, 665.3ms\n",
      "Speed: 1.0ms preprocess, 665.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132700.jpg: 384x640 2 cars, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132800.jpg: 384x640 8 cars, 1 bus, 661.9ms\n",
      "Speed: 2.0ms preprocess, 661.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_132900.jpg: 384x640 2 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133000.jpg: 384x640 6 cars, 3 buss, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133100.jpg: 384x640 5 cars, 1 tv, 667.3ms\n",
      "Speed: 2.0ms preprocess, 667.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133200.jpg: 384x640 7 cars, 1 bus, 659.1ms\n",
      "Speed: 1.0ms preprocess, 659.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133300.jpg: 384x640 1 person, 4 cars, 2 buss, 1 truck, 662.0ms\n",
      "Speed: 1.0ms preprocess, 662.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133400.jpg: 384x640 1 car, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133500.jpg: 384x640 7 cars, 2 buss, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133600.jpg: 384x640 2 buss, 669.2ms\n",
      "Speed: 2.0ms preprocess, 669.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133700.jpg: 384x640 4 cars, 4 buss, 662.8ms\n",
      "Speed: 1.0ms preprocess, 662.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133800.jpg: 384x640 5 cars, 2 buss, 660.6ms\n",
      "Speed: 2.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_133900.jpg: 384x640 4 cars, 1 bus, 664.1ms\n",
      "Speed: 1.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134000.jpg: 384x640 9 cars, 2 buss, 665.0ms\n",
      "Speed: 1.0ms preprocess, 665.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134100.jpg: 384x640 2 cars, 5 buss, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134200.jpg: 384x640 8 cars, 4 buss, 1 tv, 663.7ms\n",
      "Speed: 1.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134300.jpg: 384x640 2 cars, 2 buss, 665.5ms\n",
      "Speed: 1.0ms preprocess, 665.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134400.jpg: 384x640 8 cars, 1 bus, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134500.jpg: 384x640 5 cars, 4 buss, 661.0ms\n",
      "Speed: 1.0ms preprocess, 661.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134600.jpg: 384x640 3 cars, 2 buss, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134700.jpg: 384x640 1 person, 6 cars, 3 buss, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134800.jpg: 384x640 2 cars, 1 bus, 661.6ms\n",
      "Speed: 2.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_134900.jpg: 384x640 4 cars, 3 buss, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135000.jpg: 384x640 1 car, 663.6ms\n",
      "Speed: 2.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135100.jpg: 384x640 11 cars, 1 bus, 658.0ms\n",
      "Speed: 1.0ms preprocess, 658.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135200.jpg: 384x640 4 cars, 2 buss, 1 train, 666.1ms\n",
      "Speed: 2.0ms preprocess, 666.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135300.jpg: 384x640 3 cars, 2 buss, 681.1ms\n",
      "Speed: 1.0ms preprocess, 681.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135400.jpg: 384x640 7 cars, 4 buss, 663.0ms\n",
      "Speed: 2.0ms preprocess, 663.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135500.jpg: 384x640 2 cars, 1 bus, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135600.jpg: 384x640 8 cars, 4 buss, 661.6ms\n",
      "Speed: 1.0ms preprocess, 661.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135700.jpg: 384x640 2 cars, 2 buss, 659.8ms\n",
      "Speed: 2.0ms preprocess, 659.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135800.jpg: 384x640 8 cars, 3 buss, 1 truck, 665.8ms\n",
      "Speed: 1.0ms preprocess, 665.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_135900.jpg: 384x640 3 cars, 2 buss, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140000.jpg: 384x640 8 cars, 1 bus, 1 truck, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140100.jpg: 384x640 7 cars, 1 motorcycle, 2 buss, 665.0ms\n",
      "Speed: 1.0ms preprocess, 665.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140200.jpg: 384x640 2 cars, 664.2ms\n",
      "Speed: 2.0ms preprocess, 664.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140300.jpg: 384x640 5 cars, 2 buss, 660.5ms\n",
      "Speed: 1.0ms preprocess, 660.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140400.jpg: 384x640 3 buss, 1 truck, 663.2ms\n",
      "Speed: 1.0ms preprocess, 663.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140500.jpg: 384x640 4 cars, 5 buss, 669.2ms\n",
      "Speed: 1.0ms preprocess, 669.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140600.jpg: 384x640 5 cars, 1 bus, 658.8ms\n",
      "Speed: 1.0ms preprocess, 658.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140700.jpg: 384x640 5 cars, 2 buss, 664.1ms\n",
      "Speed: 1.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140800.jpg: 384x640 9 cars, 2 buss, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_140900.jpg: 384x640 3 cars, 1 bus, 660.7ms\n",
      "Speed: 1.0ms preprocess, 660.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141000.jpg: 384x640 3 cars, 3 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141100.jpg: 384x640 3 cars, 4 buss, 661.7ms\n",
      "Speed: 1.0ms preprocess, 661.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141200.jpg: 384x640 15 cars, 2 buss, 661.2ms\n",
      "Speed: 1.0ms preprocess, 661.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141300.jpg: 384x640 7 cars, 2 buss, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141400.jpg: 384x640 2 cars, 2 buss, 1 tv, 662.7ms\n",
      "Speed: 1.0ms preprocess, 662.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141500.jpg: 384x640 8 cars, 3 buss, 1 train, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141600.jpg: 384x640 2 cars, 4 buss, 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141700.jpg: 384x640 10 cars, 4 buss, 663.3ms\n",
      "Speed: 1.0ms preprocess, 663.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141800.jpg: 384x640 4 cars, 3 buss, 668.7ms\n",
      "Speed: 2.0ms preprocess, 668.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_141900.jpg: 384x640 13 cars, 3 buss, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142000.jpg: 384x640 7 cars, 3 buss, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142100.jpg: 384x640 3 cars, 4 buss, 663.0ms\n",
      "Speed: 1.0ms preprocess, 663.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142200.jpg: 384x640 8 cars, 2 buss, 666.8ms\n",
      "Speed: 1.0ms preprocess, 666.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142300.jpg: 384x640 1 car, 3 buss, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142400.jpg: 384x640 5 cars, 3 buss, 669.8ms\n",
      "Speed: 1.0ms preprocess, 669.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142500.jpg: 384x640 1 bus, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142600.jpg: 384x640 5 cars, 4 buss, 1 tv, 671.8ms\n",
      "Speed: 1.0ms preprocess, 671.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142700.jpg: 384x640 7 cars, 2 buss, 666.2ms\n",
      "Speed: 2.0ms preprocess, 666.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142800.jpg: 384x640 2 cars, 1 bus, 669.2ms\n",
      "Speed: 2.0ms preprocess, 669.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_142900.jpg: 384x640 8 cars, 1 bus, 664.1ms\n",
      "Speed: 1.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143000.jpg: 384x640 3 cars, 1 bus, 668.4ms\n",
      "Speed: 1.0ms preprocess, 668.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143100.jpg: 384x640 11 cars, 3 buss, 661.7ms\n",
      "Speed: 1.0ms preprocess, 661.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143200.jpg: 384x640 1 person, 2 cars, 1 bus, 1 tv, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143300.jpg: 384x640 6 cars, 3 buss, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143400.jpg: 384x640 4 cars, 1 bus, 1 train, 663.6ms\n",
      "Speed: 2.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143500.jpg: 384x640 1 car, 2 buss, 662.6ms\n",
      "Speed: 2.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143600.jpg: 384x640 5 cars, 2 buss, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143700.jpg: 384x640 5 cars, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143800.jpg: 384x640 12 cars, 1 bus, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_143900.jpg: 384x640 1 bus, 1 tv, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144000.jpg: 384x640 9 cars, 2 buss, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144100.jpg: 384x640 13 cars, 3 buss, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144200.jpg: 384x640 3 cars, 1 tv, 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144300.jpg: 384x640 3 cars, 1 truck, 662.9ms\n",
      "Speed: 2.0ms preprocess, 662.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144400.jpg: 384x640 4 cars, 664.0ms\n",
      "Speed: 1.0ms preprocess, 664.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144500.jpg: 384x640 10 cars, 2 buss, 661.6ms\n",
      "Speed: 2.0ms preprocess, 661.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144600.jpg: 384x640 6 cars, 1 bus, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144700.jpg: 384x640 1 person, 12 cars, 1 bus, 684.6ms\n",
      "Speed: 2.0ms preprocess, 684.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144800.jpg: 384x640 10 cars, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_144900.jpg: 384x640 3 cars, 2 buss, 661.6ms\n",
      "Speed: 1.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145000.jpg: 384x640 3 cars, 3 buss, 660.2ms\n",
      "Speed: 2.0ms preprocess, 660.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145100.jpg: 384x640 (no detections), 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145200.jpg: 384x640 9 cars, 4 buss, 1 truck, 665.0ms\n",
      "Speed: 1.0ms preprocess, 665.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145300.jpg: 384x640 1 person, 3 cars, 3 buss, 1 tv, 662.6ms\n",
      "Speed: 2.0ms preprocess, 662.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145400.jpg: 384x640 12 cars, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145500.jpg: 384x640 10 cars, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145600.jpg: 384x640 2 cars, 1 bus, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145700.jpg: 384x640 7 cars, 1 bus, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145800.jpg: 384x640 1 car, 1 bus, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_145900.jpg: 384x640 6 cars, 1 bus, 661.0ms\n",
      "Speed: 1.0ms preprocess, 661.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150000.jpg: 384x640 6 cars, 3 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150100.jpg: 384x640 1 person, 4 cars, 1 bus, 660.6ms\n",
      "Speed: 1.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150200.jpg: 384x640 1 person, 5 cars, 4 buss, 1 tv, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150300.jpg: 384x640 2 cars, 1 bus, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150400.jpg: 384x640 10 cars, 1 bus, 659.0ms\n",
      "Speed: 2.0ms preprocess, 659.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150500.jpg: 384x640 2 cars, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150600.jpg: 384x640 10 cars, 1 bus, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150700.jpg: 384x640 3 cars, 5 buss, 657.6ms\n",
      "Speed: 2.0ms preprocess, 657.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150800.jpg: 384x640 6 cars, 3 buss, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_150900.jpg: 384x640 3 cars, 3 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151000.jpg: 384x640 2 cars, 3 buss, 660.1ms\n",
      "Speed: 1.0ms preprocess, 660.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151100.jpg: 384x640 8 cars, 2 buss, 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151200.jpg: 384x640 3 buss, 1 tv, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151300.jpg: 384x640 12 cars, 2 buss, 659.6ms\n",
      "Speed: 1.0ms preprocess, 659.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151400.jpg: 384x640 1 car, 1 bus, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151500.jpg: 384x640 7 cars, 3 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151600.jpg: 384x640 7 cars, 2 buss, 1 tv, 660.4ms\n",
      "Speed: 1.0ms preprocess, 660.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151700.jpg: 384x640 4 cars, 1 bus, 664.0ms\n",
      "Speed: 2.0ms preprocess, 664.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151800.jpg: 384x640 7 cars, 4 buss, 663.0ms\n",
      "Speed: 1.0ms preprocess, 663.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_151900.jpg: 384x640 2 cars, 2 buss, 659.1ms\n",
      "Speed: 1.5ms preprocess, 659.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152000.jpg: 384x640 10 cars, 1 bus, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152100.jpg: 384x640 3 cars, 1 bus, 1 truck, 1 tv, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152200.jpg: 384x640 8 cars, 3 buss, 1 tv, 660.6ms\n",
      "Speed: 2.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152300.jpg: 384x640 8 cars, 3 buss, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152400.jpg: 384x640 1 car, 2 buss, 662.1ms\n",
      "Speed: 2.0ms preprocess, 662.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152500.jpg: 384x640 8 cars, 3 buss, 657.0ms\n",
      "Speed: 1.0ms preprocess, 657.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152600.jpg: 384x640 2 cars, 3 buss, 1 tv, 663.6ms\n",
      "Speed: 2.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152700.jpg: 384x640 14 cars, 5 buss, 660.6ms\n",
      "Speed: 2.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152800.jpg: 384x640 6 cars, 4 buss, 1 truck, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_152900.jpg: 384x640 8 cars, 4 buss, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153000.jpg: 384x640 14 cars, 2 buss, 666.8ms\n",
      "Speed: 1.0ms preprocess, 666.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153100.jpg: 384x640 6 cars, 1 bus, 662.0ms\n",
      "Speed: 2.0ms preprocess, 662.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153200.jpg: 384x640 13 cars, 2 buss, 1 tv, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153300.jpg: 384x640 4 cars, 3 buss, 659.6ms\n",
      "Speed: 2.0ms preprocess, 659.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153400.jpg: 384x640 14 cars, 3 buss, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153500.jpg: 384x640 5 cars, 1 bus, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153600.jpg: 384x640 9 cars, 1 truck, 666.9ms\n",
      "Speed: 2.0ms preprocess, 666.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153700.jpg: 384x640 9 cars, 682.5ms\n",
      "Speed: 1.0ms preprocess, 682.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153800.jpg: 384x640 1 car, 698.8ms\n",
      "Speed: 1.0ms preprocess, 698.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_153900.jpg: 384x640 7 cars, 2 buss, 1 tv, 674.1ms\n",
      "Speed: 1.0ms preprocess, 674.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154000.jpg: 384x640 (no detections), 682.0ms\n",
      "Speed: 1.0ms preprocess, 682.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154100.jpg: 384x640 9 cars, 3 buss, 683.5ms\n",
      "Speed: 1.0ms preprocess, 683.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154200.jpg: 384x640 1 bus, 1 tv, 688.5ms\n",
      "Speed: 2.0ms preprocess, 688.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154300.jpg: 384x640 5 cars, 2 buss, 681.1ms\n",
      "Speed: 1.0ms preprocess, 681.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154400.jpg: 384x640 5 cars, 1 bus, 678.1ms\n",
      "Speed: 2.0ms preprocess, 678.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154500.jpg: 384x640 1 car, 680.6ms\n",
      "Speed: 1.0ms preprocess, 680.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154600.jpg: 384x640 13 cars, 1 bus, 677.6ms\n",
      "Speed: 2.0ms preprocess, 677.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154700.jpg: 384x640 5 cars, 674.7ms\n",
      "Speed: 1.0ms preprocess, 674.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154800.jpg: 384x640 16 cars, 3 buss, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_154900.jpg: 384x640 5 cars, 3 buss, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155000.jpg: 384x640 11 cars, 2 buss, 669.0ms\n",
      "Speed: 1.0ms preprocess, 669.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155100.jpg: 384x640 7 cars, 1 bus, 673.9ms\n",
      "Speed: 2.0ms preprocess, 673.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155200.jpg: 384x640 4 cars, 1 bus, 671.1ms\n",
      "Speed: 1.0ms preprocess, 671.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155300.jpg: 384x640 13 cars, 2 buss, 670.7ms\n",
      "Speed: 2.0ms preprocess, 670.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155400.jpg: 384x640 6 cars, 1 bus, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155500.jpg: 384x640 16 cars, 2 buss, 1 truck, 668.7ms\n",
      "Speed: 1.0ms preprocess, 668.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155600.jpg: 384x640 1 car, 3 buss, 1 tv, 667.4ms\n",
      "Speed: 2.0ms preprocess, 667.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155700.jpg: 384x640 7 cars, 4 buss, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155800.jpg: 384x640 10 cars, 3 buss, 1 truck, 664.3ms\n",
      "Speed: 1.0ms preprocess, 664.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_155900.jpg: 384x640 4 cars, 1 bus, 673.3ms\n",
      "Speed: 3.0ms preprocess, 673.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160000.jpg: 384x640 11 cars, 3 buss, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160100.jpg: 384x640 1 car, 2 buss, 668.4ms\n",
      "Speed: 1.0ms preprocess, 668.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160200.jpg: 384x640 10 cars, 2 buss, 1 tv, 668.0ms\n",
      "Speed: 1.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160300.jpg: 384x640 6 cars, 3 buss, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160400.jpg: 384x640 4 cars, 4 buss, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160500.jpg: 384x640 8 cars, 3 buss, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160600.jpg: 384x640 1 car, 2 buss, 663.7ms\n",
      "Speed: 2.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160700.jpg: 384x640 7 cars, 4 buss, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160800.jpg: 384x640 1 car, 2 buss, 668.7ms\n",
      "Speed: 1.0ms preprocess, 668.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_160900.jpg: 384x640 9 cars, 6 buss, 667.2ms\n",
      "Speed: 1.0ms preprocess, 667.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161000.jpg: 384x640 6 cars, 674.1ms\n",
      "Speed: 1.0ms preprocess, 674.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161100.jpg: 384x640 5 cars, 3 buss, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161200.jpg: 384x640 3 cars, 6 buss, 1 tv, 664.2ms\n",
      "Speed: 1.0ms preprocess, 664.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161300.jpg: 384x640 1 car, 4 buss, 671.7ms\n",
      "Speed: 2.0ms preprocess, 671.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161400.jpg: 384x640 9 cars, 2 buss, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161500.jpg: 384x640 2 cars, 1 bus, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161600.jpg: 384x640 9 cars, 2 buss, 1 truck, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161700.jpg: 384x640 6 cars, 1 bus, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161800.jpg: 384x640 8 cars, 1 train, 665.4ms\n",
      "Speed: 1.0ms preprocess, 665.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_161900.jpg: 384x640 10 cars, 1 bus, 668.2ms\n",
      "Speed: 2.0ms preprocess, 668.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162000.jpg: 384x640 4 cars, 2 buss, 667.3ms\n",
      "Speed: 1.0ms preprocess, 667.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162100.jpg: 384x640 5 cars, 5 buss, 1 tv, 666.0ms\n",
      "Speed: 1.0ms preprocess, 666.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162200.jpg: 384x640 3 cars, 1 bus, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162300.jpg: 384x640 9 cars, 4 buss, 666.9ms\n",
      "Speed: 2.0ms preprocess, 666.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162400.jpg: 384x640 6 cars, 1 bus, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162500.jpg: 384x640 11 cars, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162600.jpg: 384x640 9 cars, 4 buss, 665.8ms\n",
      "Speed: 2.0ms preprocess, 665.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162700.jpg: 384x640 2 cars, 1 bus, 664.3ms\n",
      "Speed: 1.0ms preprocess, 664.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162800.jpg: 384x640 8 cars, 2 buss, 667.1ms\n",
      "Speed: 2.0ms preprocess, 667.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_162900.jpg: 384x640 3 cars, 660.4ms\n",
      "Speed: 1.0ms preprocess, 660.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163000.jpg: 384x640 12 cars, 3 buss, 1 tv, 666.8ms\n",
      "Speed: 1.0ms preprocess, 666.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163100.jpg: 384x640 3 cars, 3 buss, 668.9ms\n",
      "Speed: 2.0ms preprocess, 668.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163200.jpg: 384x640 9 cars, 1 bus, 1 tv, 682.6ms\n",
      "Speed: 1.0ms preprocess, 682.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163300.jpg: 384x640 13 cars, 2 buss, 667.7ms\n",
      "Speed: 2.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163400.jpg: 384x640 3 cars, 1 bus, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163500.jpg: 384x640 5 cars, 2 buss, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163600.jpg: 384x640 1 bus, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163700.jpg: 384x640 7 cars, 2 buss, 664.0ms\n",
      "Speed: 1.0ms preprocess, 664.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163800.jpg: 384x640 7 cars, 2 buss, 659.1ms\n",
      "Speed: 1.5ms preprocess, 659.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_163900.jpg: 384x640 8 cars, 3 buss, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164000.jpg: 384x640 7 cars, 3 buss, 659.6ms\n",
      "Speed: 1.0ms preprocess, 659.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164100.jpg: 384x640 3 cars, 1 bus, 656.6ms\n",
      "Speed: 1.0ms preprocess, 656.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164200.jpg: 384x640 1 person, 9 cars, 1 bus, 1 tv, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164300.jpg: 384x640 2 buss, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164400.jpg: 384x640 14 cars, 3 buss, 666.1ms\n",
      "Speed: 1.5ms preprocess, 666.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164500.jpg: 384x640 5 cars, 2 buss, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164600.jpg: 384x640 11 cars, 1 bus, 1 tv, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164700.jpg: 384x640 8 cars, 1 bus, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164800.jpg: 384x640 2 cars, 2 buss, 664.7ms\n",
      "Speed: 2.0ms preprocess, 664.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_164900.jpg: 384x640 11 cars, 3 buss, 662.7ms\n",
      "Speed: 1.0ms preprocess, 662.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165000.jpg: 384x640 2 cars, 1 bus, 658.0ms\n",
      "Speed: 1.0ms preprocess, 658.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165100.jpg: 384x640 9 cars, 2 buss, 666.0ms\n",
      "Speed: 1.0ms preprocess, 666.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165200.jpg: 384x640 4 cars, 1 bus, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165300.jpg: 384x640 9 cars, 4 buss, 1 tv, 671.6ms\n",
      "Speed: 2.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165400.jpg: 384x640 5 cars, 2 buss, 668.7ms\n",
      "Speed: 1.0ms preprocess, 668.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165500.jpg: 384x640 1 car, 663.6ms\n",
      "Speed: 2.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165600.jpg: 384x640 9 cars, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165700.jpg: 384x640 2 cars, 1 bus, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165800.jpg: 384x640 10 cars, 4 buss, 670.0ms\n",
      "Speed: 2.0ms preprocess, 670.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_165900.jpg: 384x640 1 car, 1 bus, 1 tv, 663.0ms\n",
      "Speed: 2.0ms preprocess, 663.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170000.jpg: 384x640 9 cars, 3 buss, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170100.jpg: 384x640 7 cars, 4 buss, 1 tv, 661.6ms\n",
      "Speed: 2.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170200.jpg: 384x640 (no detections), 667.4ms\n",
      "Speed: 1.0ms preprocess, 667.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170300.jpg: 384x640 9 cars, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170400.jpg: 384x640 1 car, 1 bus, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170500.jpg: 384x640 10 cars, 1 bus, 1 truck, 671.1ms\n",
      "Speed: 2.0ms preprocess, 671.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170600.jpg: 384x640 12 cars, 671.2ms\n",
      "Speed: 2.0ms preprocess, 671.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170700.jpg: 384x640 8 cars, 1 bus, 1 train, 662.7ms\n",
      "Speed: 2.0ms preprocess, 662.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170800.jpg: 384x640 11 cars, 2 buss, 662.9ms\n",
      "Speed: 1.0ms preprocess, 662.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_170900.jpg: 384x640 2 cars, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171000.jpg: 384x640 7 cars, 2 buss, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171100.jpg: 384x640 5 buss, 667.4ms\n",
      "Speed: 2.0ms preprocess, 667.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171200.jpg: 384x640 11 cars, 3 buss, 1 tv, 669.7ms\n",
      "Speed: 1.0ms preprocess, 669.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171300.jpg: 384x640 1 car, 2 buss, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171400.jpg: 384x640 5 cars, 668.3ms\n",
      "Speed: 1.0ms preprocess, 668.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171500.jpg: 384x640 6 cars, 1 bus, 672.1ms\n",
      "Speed: 2.0ms preprocess, 672.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171600.jpg: 384x640 1 car, 1 bus, 665.2ms\n",
      "Speed: 2.0ms preprocess, 665.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171700.jpg: 384x640 6 cars, 3 buss, 1 truck, 670.4ms\n",
      "Speed: 1.0ms preprocess, 670.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171800.jpg: 384x640 2 cars, 1 bus, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_171900.jpg: 384x640 12 cars, 1 bus, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172000.jpg: 384x640 2 cars, 3 buss, 674.5ms\n",
      "Speed: 1.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172100.jpg: 384x640 7 cars, 1 motorcycle, 1 bus, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172200.jpg: 384x640 3 cars, 5 buss, 672.3ms\n",
      "Speed: 1.0ms preprocess, 672.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172300.jpg: 384x640 2 buss, 684.6ms\n",
      "Speed: 1.0ms preprocess, 684.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172400.jpg: 384x640 8 cars, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172500.jpg: 384x640 2 cars, 1 bus, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172600.jpg: 384x640 9 cars, 2 buss, 665.8ms\n",
      "Speed: 2.0ms preprocess, 665.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172700.jpg: 384x640 5 cars, 2 buss, 1 truck, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172800.jpg: 384x640 9 cars, 668.3ms\n",
      "Speed: 1.0ms preprocess, 668.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_172900.jpg: 384x640 9 cars, 2 buss, 667.5ms\n",
      "Speed: 2.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173000.jpg: 384x640 3 cars, 664.7ms\n",
      "Speed: 2.0ms preprocess, 664.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173100.jpg: 384x640 8 cars, 1 bus, 1 tv, 669.7ms\n",
      "Speed: 2.0ms preprocess, 669.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173200.jpg: 384x640 1 car, 664.1ms\n",
      "Speed: 1.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173300.jpg: 384x640 7 cars, 4 buss, 664.2ms\n",
      "Speed: 1.0ms preprocess, 664.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173400.jpg: 384x640 8 cars, 1 bus, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173500.jpg: 384x640 7 cars, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173600.jpg: 384x640 9 cars, 1 bus, 669.8ms\n",
      "Speed: 1.0ms preprocess, 669.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173700.jpg: 384x640 3 cars, 3 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173800.jpg: 384x640 8 cars, 2 buss, 667.3ms\n",
      "Speed: 1.0ms preprocess, 667.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_173900.jpg: 384x640 3 cars, 3 buss, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174000.jpg: 384x640 7 cars, 2 buss, 668.8ms\n",
      "Speed: 1.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174100.jpg: 384x640 8 cars, 3 buss, 661.2ms\n",
      "Speed: 1.0ms preprocess, 661.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174200.jpg: 384x640 7 cars, 4 buss, 668.2ms\n",
      "Speed: 1.0ms preprocess, 668.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174300.jpg: 384x640 8 cars, 5 buss, 657.6ms\n",
      "Speed: 2.0ms preprocess, 657.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174400.jpg: 384x640 1 car, 3 buss, 661.1ms\n",
      "Speed: 2.0ms preprocess, 661.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174500.jpg: 384x640 4 cars, 5 buss, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174600.jpg: 384x640 3 cars, 1 bus, 660.6ms\n",
      "Speed: 1.0ms preprocess, 660.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174700.jpg: 384x640 9 cars, 1 bus, 1 traffic light, 660.2ms\n",
      "Speed: 1.0ms preprocess, 660.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174800.jpg: 384x640 6 cars, 1 bus, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_174900.jpg: 384x640 1 person, 7 cars, 1 bus, 666.9ms\n",
      "Speed: 2.0ms preprocess, 666.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175000.jpg: 384x640 3 cars, 4 buss, 3 trucks, 661.6ms\n",
      "Speed: 2.0ms preprocess, 661.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175100.jpg: 384x640 1 car, 661.3ms\n",
      "Speed: 2.0ms preprocess, 661.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175200.jpg: 384x640 7 cars, 1 bus, 665.7ms\n",
      "Speed: 2.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175300.jpg: 384x640 2 cars, 2 buss, 660.0ms\n",
      "Speed: 1.0ms preprocess, 660.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175400.jpg: 384x640 10 cars, 2 buss, 665.3ms\n",
      "Speed: 1.0ms preprocess, 665.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175500.jpg: 384x640 6 cars, 2 buss, 663.7ms\n",
      "Speed: 2.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175600.jpg: 384x640 6 cars, 1 bus, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175700.jpg: 384x640 9 cars, 666.7ms\n",
      "Speed: 2.0ms preprocess, 666.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175800.jpg: 384x640 2 cars, 1 bus, 662.7ms\n",
      "Speed: 1.0ms preprocess, 662.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_175900.jpg: 384x640 7 cars, 1 bus, 1 tv, 662.1ms\n",
      "Speed: 2.0ms preprocess, 662.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180000.jpg: 384x640 7 cars, 4 buss, 1 truck, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180100.jpg: 384x640 3 cars, 1 bus, 663.3ms\n",
      "Speed: 1.0ms preprocess, 663.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180200.jpg: 384x640 8 cars, 2 buss, 1 tv, 660.8ms\n",
      "Speed: 1.0ms preprocess, 660.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180300.jpg: 384x640 1 car, 2 buss, 664.8ms\n",
      "Speed: 2.0ms preprocess, 664.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180400.jpg: 384x640 12 cars, 1 bus, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180500.jpg: 384x640 1 tv, 660.7ms\n",
      "Speed: 1.0ms preprocess, 660.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180600.jpg: 384x640 2 cars, 664.2ms\n",
      "Speed: 1.0ms preprocess, 664.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180700.jpg: 384x640 6 cars, 2 buss, 1 traffic light, 662.1ms\n",
      "Speed: 2.0ms preprocess, 662.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180800.jpg: 384x640 2 cars, 3 buss, 662.7ms\n",
      "Speed: 2.0ms preprocess, 662.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_180900.jpg: 384x640 11 cars, 2 buss, 663.7ms\n",
      "Speed: 2.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181000.jpg: 384x640 1 car, 3 buss, 667.8ms\n",
      "Speed: 2.0ms preprocess, 667.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181100.jpg: 384x640 7 cars, 2 motorcycles, 4 buss, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181200.jpg: 384x640 6 cars, 3 buss, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181300.jpg: 384x640 1 car, 3 buss, 1 truck, 661.4ms\n",
      "Speed: 1.0ms preprocess, 661.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181400.jpg: 384x640 6 cars, 1 bus, 2 trucks, 1 tv, 666.2ms\n",
      "Speed: 2.0ms preprocess, 666.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181500.jpg: 384x640 1 tv, 664.8ms\n",
      "Speed: 2.0ms preprocess, 664.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181600.jpg: 384x640 8 cars, 2 buss, 1 traffic light, 1 tv, 660.0ms\n",
      "Speed: 1.0ms preprocess, 660.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181700.jpg: 384x640 2 cars, 2 buss, 1 tv, 661.7ms\n",
      "Speed: 1.0ms preprocess, 661.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181800.jpg: 384x640 11 cars, 1 bus, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_181900.jpg: 384x640 8 cars, 1 bus, 1 truck, 1 tv, 663.4ms\n",
      "Speed: 1.0ms preprocess, 663.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182000.jpg: 384x640 1 car, 2 buss, 1 truck, 664.1ms\n",
      "Speed: 1.0ms preprocess, 664.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182100.jpg: 384x640 5 cars, 3 buss, 1 truck, 1 tv, 663.9ms\n",
      "Speed: 1.0ms preprocess, 663.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182200.jpg: 384x640 1 bus, 1 tv, 660.5ms\n",
      "Speed: 2.0ms preprocess, 660.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182300.jpg: 384x640 4 cars, 2 buss, 1 traffic light, 1 tv, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182400.jpg: 384x640 1 bus, 1 tv, 662.8ms\n",
      "Speed: 1.0ms preprocess, 662.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182500.jpg: 384x640 4 cars, 1 bus, 1 truck, 659.2ms\n",
      "Speed: 2.0ms preprocess, 659.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182600.jpg: 384x640 6 cars, 1 bus, 666.3ms\n",
      "Speed: 2.0ms preprocess, 666.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182700.jpg: 384x640 1 car, 1 bus, 661.5ms\n",
      "Speed: 1.5ms preprocess, 661.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182800.jpg: 384x640 6 cars, 3 buss, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_182900.jpg: 384x640 (no detections), 660.9ms\n",
      "Speed: 1.0ms preprocess, 660.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183000.jpg: 384x640 8 cars, 674.6ms\n",
      "Speed: 2.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183100.jpg: 384x640 1 tv, 672.6ms\n",
      "Speed: 2.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183200.jpg: 384x640 9 cars, 1 bus, 1 tv, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183300.jpg: 384x640 4 cars, 2 buss, 1 tv, 667.0ms\n",
      "Speed: 2.0ms preprocess, 667.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183400.jpg: 384x640 2 cars, 1 bus, 1 tv, 673.0ms\n",
      "Speed: 1.0ms preprocess, 673.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183500.jpg: 384x640 6 cars, 4 buss, 670.0ms\n",
      "Speed: 2.0ms preprocess, 670.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183600.jpg: 384x640 2 cars, 1 bus, 1 tv, 676.0ms\n",
      "Speed: 1.5ms preprocess, 676.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183700.jpg: 384x640 11 cars, 3 buss, 1 tv, 679.5ms\n",
      "Speed: 1.0ms preprocess, 679.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183800.jpg: 384x640 2 cars, 1 tv, 668.6ms\n",
      "Speed: 2.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_183900.jpg: 384x640 7 cars, 1 bus, 1 tv, 670.5ms\n",
      "Speed: 1.0ms preprocess, 670.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184000.jpg: 384x640 7 cars, 1 tv, 678.5ms\n",
      "Speed: 1.0ms preprocess, 678.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184100.jpg: 384x640 2 cars, 1 tv, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184200.jpg: 384x640 5 cars, 1 tv, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184300.jpg: 384x640 2 cars, 1 bus, 1 tv, 672.5ms\n",
      "Speed: 2.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184400.jpg: 384x640 5 cars, 1 tv, 675.5ms\n",
      "Speed: 2.0ms preprocess, 675.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184500.jpg: 384x640 1 car, 1 bus, 1 tv, 669.5ms\n",
      "Speed: 1.0ms preprocess, 669.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184600.jpg: 384x640 12 cars, 3 buss, 1 tv, 670.5ms\n",
      "Speed: 2.0ms preprocess, 670.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184700.jpg: 384x640 4 cars, 2 buss, 670.5ms\n",
      "Speed: 2.0ms preprocess, 670.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184800.jpg: 384x640 1 bus, 1 tv, 670.0ms\n",
      "Speed: 1.0ms preprocess, 670.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_184900.jpg: 384x640 9 cars, 1 bus, 674.0ms\n",
      "Speed: 1.0ms preprocess, 674.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185000.jpg: 384x640 1 tv, 669.0ms\n",
      "Speed: 1.0ms preprocess, 669.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185100.jpg: 384x640 2 cars, 1 bus, 1 truck, 1 tv, 667.0ms\n",
      "Speed: 1.5ms preprocess, 667.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185200.jpg: 384x640 1 tv, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185300.jpg: 384x640 5 cars, 1 bus, 1 tv, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185400.jpg: 384x640 3 cars, 1 bus, 1 tv, 672.5ms\n",
      "Speed: 2.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185500.jpg: 384x640 2 cars, 1 tv, 679.5ms\n",
      "Speed: 1.0ms preprocess, 679.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185600.jpg: 384x640 4 cars, 2 buss, 674.5ms\n",
      "Speed: 1.0ms preprocess, 674.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185700.jpg: 384x640 3 cars, 1 tv, 666.5ms\n",
      "Speed: 2.0ms preprocess, 666.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185800.jpg: 384x640 3 cars, 2 buss, 1 tv, 668.5ms\n",
      "Speed: 2.0ms preprocess, 668.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_185900.jpg: 384x640 2 cars, 1 bus, 1 tv, 668.4ms\n",
      "Speed: 1.0ms preprocess, 668.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190000.jpg: 384x640 8 cars, 2 buss, 667.7ms\n",
      "Speed: 2.0ms preprocess, 667.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190100.jpg: 384x640 2 cars, 3 buss, 1 tv, 669.0ms\n",
      "Speed: 1.0ms preprocess, 669.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190200.jpg: 384x640 1 traffic light, 1 tv, 667.2ms\n",
      "Speed: 1.0ms preprocess, 667.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190300.jpg: 384x640 4 cars, 2 buss, 1 tv, 671.7ms\n",
      "Speed: 1.0ms preprocess, 671.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190400.jpg: 384x640 1 car, 1 bus, 1 tv, 676.6ms\n",
      "Speed: 2.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190500.jpg: 384x640 4 cars, 1 truck, 1 tv, 671.6ms\n",
      "Speed: 2.0ms preprocess, 671.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190600.jpg: 384x640 1 bus, 1 tv, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190700.jpg: 384x640 7 cars, 2 buss, 1 tv, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190800.jpg: 384x640 2 cars, 1 bus, 1 tv, 669.3ms\n",
      "Speed: 1.0ms preprocess, 669.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_190900.jpg: 384x640 3 cars, 2 buss, 1 tv, 666.0ms\n",
      "Speed: 1.0ms preprocess, 666.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191000.jpg: 384x640 7 cars, 2 buss, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191100.jpg: 384x640 1 car, 1 tv, 674.1ms\n",
      "Speed: 1.0ms preprocess, 674.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191200.jpg: 384x640 4 cars, 3 buss, 1 tv, 667.1ms\n",
      "Speed: 1.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191300.jpg: 384x640 1 car, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191400.jpg: 384x640 7 cars, 1 bus, 1 tv, 679.8ms\n",
      "Speed: 1.0ms preprocess, 679.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191500.jpg: 384x640 1 car, 1 bus, 668.7ms\n",
      "Speed: 1.0ms preprocess, 668.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191600.jpg: 384x640 2 cars, 1 bus, 1 tv, 659.8ms\n",
      "Speed: 1.0ms preprocess, 659.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191700.jpg: 384x640 6 cars, 1 bus, 1 truck, 670.8ms\n",
      "Speed: 1.0ms preprocess, 670.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191800.jpg: 384x640 3 cars, 3 buss, 669.9ms\n",
      "Speed: 2.0ms preprocess, 669.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_191900.jpg: 384x640 9 cars, 1 truck, 1 tv, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192000.jpg: 384x640 2 cars, 1 tv, 673.6ms\n",
      "Speed: 1.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192100.jpg: 384x640 9 cars, 1 bus, 1 tv, 667.1ms\n",
      "Speed: 2.0ms preprocess, 667.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192200.jpg: 384x640 1 person, 1 car, 2 buss, 663.1ms\n",
      "Speed: 1.0ms preprocess, 663.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192300.jpg: 384x640 1 car, 1 bus, 1 tv, 673.8ms\n",
      "Speed: 1.0ms preprocess, 673.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192400.jpg: 384x640 3 cars, 4 buss, 668.9ms\n",
      "Speed: 1.0ms preprocess, 668.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192500.jpg: 384x640 (no detections), 662.8ms\n",
      "Speed: 1.0ms preprocess, 662.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192600.jpg: 384x640 3 cars, 1 bus, 1 tv, 671.7ms\n",
      "Speed: 2.0ms preprocess, 671.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192700.jpg: 384x640 1 car, 1 tv, 669.8ms\n",
      "Speed: 2.0ms preprocess, 669.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192800.jpg: 384x640 10 cars, 2 buss, 1 tv, 662.7ms\n",
      "Speed: 2.0ms preprocess, 662.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_192900.jpg: 384x640 4 cars, 666.1ms\n",
      "Speed: 2.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193000.jpg: 384x640 4 cars, 1 tv, 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193100.jpg: 384x640 4 cars, 1 bus, 1 tv, 666.3ms\n",
      "Speed: 1.0ms preprocess, 666.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193200.jpg: 384x640 1 car, 1 tv, 671.7ms\n",
      "Speed: 1.0ms preprocess, 671.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193300.jpg: 384x640 4 cars, 3 buss, 1 tv, 668.7ms\n",
      "Speed: 2.0ms preprocess, 668.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193400.jpg: 384x640 1 bus, 1 tv, 664.8ms\n",
      "Speed: 1.0ms preprocess, 664.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193500.jpg: 384x640 6 cars, 2 buss, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193600.jpg: 384x640 3 cars, 2 buss, 1 tv, 672.7ms\n",
      "Speed: 1.0ms preprocess, 672.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193700.jpg: 384x640 1 person, 3 cars, 1 tv, 662.7ms\n",
      "Speed: 1.0ms preprocess, 662.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193800.jpg: 384x640 2 cars, 2 buss, 1 tv, 674.2ms\n",
      "Speed: 1.0ms preprocess, 674.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_193900.jpg: 384x640 1 car, 1 tv, 680.1ms\n",
      "Speed: 1.0ms preprocess, 680.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194000.jpg: 384x640 6 cars, 3 buss, 1 tv, 671.9ms\n",
      "Speed: 1.0ms preprocess, 671.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194100.jpg: 384x640 1 tv, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194200.jpg: 384x640 10 cars, 2 buss, 1 truck, 1 tv, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194300.jpg: 384x640 1 car, 1 bus, 1 traffic light, 1 tv, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194400.jpg: 384x640 1 person, 1 bus, 2 trucks, 1 traffic light, 1 tv, 670.8ms\n",
      "Speed: 1.0ms preprocess, 670.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194500.jpg: 384x640 3 cars, 4 buss, 669.7ms\n",
      "Speed: 1.0ms preprocess, 669.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194600.jpg: 384x640 2 cars, 667.7ms\n",
      "Speed: 2.0ms preprocess, 667.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194700.jpg: 384x640 3 cars, 2 buss, 1 tv, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194800.jpg: 384x640 1 car, 1 tv, 673.3ms\n",
      "Speed: 1.0ms preprocess, 673.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_194900.jpg: 384x640 8 cars, 1 bus, 1 tv, 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195000.jpg: 384x640 1 bus, 1 tv, 665.1ms\n",
      "Speed: 2.0ms preprocess, 665.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195100.jpg: 384x640 3 cars, 1 tv, 668.9ms\n",
      "Speed: 2.0ms preprocess, 668.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195200.jpg: 384x640 4 cars, 1 truck, 1 tv, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195300.jpg: 384x640 1 car, 1 tv, 669.9ms\n",
      "Speed: 1.0ms preprocess, 669.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195400.jpg: 384x640 1 car, 5 buss, 666.9ms\n",
      "Speed: 1.0ms preprocess, 666.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195500.jpg: 384x640 2 cars, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195600.jpg: 384x640 9 cars, 1 bus, 1 traffic light, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195700.jpg: 384x640 1 person, 1 car, 1 bus, 673.1ms\n",
      "Speed: 1.0ms preprocess, 673.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195800.jpg: 384x640 1 person, 7 cars, 2 trucks, 1 tv, 669.0ms\n",
      "Speed: 1.0ms preprocess, 669.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_195900.jpg: 384x640 4 cars, 665.1ms\n",
      "Speed: 1.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200000.jpg: 384x640 2 cars, 668.6ms\n",
      "Speed: 2.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200100.jpg: 384x640 6 cars, 1 bus, 1 tv, 668.4ms\n",
      "Speed: 1.0ms preprocess, 668.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200200.jpg: 384x640 1 car, 1 tv, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200300.jpg: 384x640 5 cars, 1 bus, 1 tv, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200400.jpg: 384x640 4 cars, 2 buss, 2 trucks, 1 tv, 670.7ms\n",
      "Speed: 2.0ms preprocess, 670.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200500.jpg: 384x640 8 cars, 1 tv, 662.6ms\n",
      "Speed: 1.0ms preprocess, 662.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200600.jpg: 384x640 3 cars, 3 buss, 1 tv, 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200700.jpg: 384x640 1 bus, 1 tv, 668.0ms\n",
      "Speed: 1.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200800.jpg: 384x640 1 car, 1 bus, 1 truck, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_200900.jpg: 384x640 1 car, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201000.jpg: 384x640 6 cars, 1 bus, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201100.jpg: 384x640 2 cars, 1 bus, 1 tv, 666.4ms\n",
      "Speed: 1.0ms preprocess, 666.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201200.jpg: 384x640 4 cars, 1 truck, 1 tv, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201300.jpg: 384x640 6 cars, 3 buss, 1 tv, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201400.jpg: 384x640 1 car, 1 bus, 1 tv, 662.1ms\n",
      "Speed: 1.0ms preprocess, 662.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201500.jpg: 384x640 3 cars, 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201600.jpg: 384x640 1 tv, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201700.jpg: 384x640 4 cars, 1 truck, 667.8ms\n",
      "Speed: 1.0ms preprocess, 667.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201800.jpg: 384x640 2 cars, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_201900.jpg: 384x640 1 car, 3 buss, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202000.jpg: 384x640 6 cars, 2 buss, 667.9ms\n",
      "Speed: 1.0ms preprocess, 667.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202100.jpg: 384x640 2 cars, 1 tv, 666.8ms\n",
      "Speed: 2.0ms preprocess, 666.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202200.jpg: 384x640 3 cars, 1 tv, 673.3ms\n",
      "Speed: 2.0ms preprocess, 673.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202300.jpg: 384x640 2 cars, 1 tv, 669.7ms\n",
      "Speed: 1.0ms preprocess, 669.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202400.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 1 tv, 664.2ms\n",
      "Speed: 1.0ms preprocess, 664.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202500.jpg: 384x640 3 cars, 1 tv, 679.8ms\n",
      "Speed: 1.0ms preprocess, 679.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202600.jpg: 384x640 5 cars, 1 bus, 1 tv, 667.3ms\n",
      "Speed: 2.0ms preprocess, 667.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202700.jpg: 384x640 5 cars, 1 bus, 667.3ms\n",
      "Speed: 1.0ms preprocess, 667.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202800.jpg: 384x640 2 cars, 1 truck, 672.8ms\n",
      "Speed: 1.0ms preprocess, 672.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_202900.jpg: 384x640 1 car, 1 truck, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203000.jpg: 384x640 1 tv, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203100.jpg: 384x640 6 cars, 2 buss, 664.0ms\n",
      "Speed: 1.0ms preprocess, 664.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203200.jpg: 384x640 3 cars, 1 tv, 673.1ms\n",
      "Speed: 2.0ms preprocess, 673.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203300.jpg: 384x640 2 cars, 1 tv, 665.8ms\n",
      "Speed: 2.0ms preprocess, 665.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203400.jpg: 384x640 5 cars, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203500.jpg: 384x640 2 cars, 1 bus, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203600.jpg: 384x640 4 cars, 3 buss, 1 tv, 668.0ms\n",
      "Speed: 1.0ms preprocess, 668.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203700.jpg: 384x640 1 car, 2 buss, 1 tv, 667.1ms\n",
      "Speed: 1.0ms preprocess, 667.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203800.jpg: 384x640 4 cars, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_203900.jpg: 384x640 2 cars, 1 tv, 669.8ms\n",
      "Speed: 1.0ms preprocess, 669.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204000.jpg: 384x640 8 cars, 1 bus, 1 truck, 1 traffic light, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204100.jpg: 384x640 4 cars, 669.1ms\n",
      "Speed: 1.0ms preprocess, 669.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204200.jpg: 384x640 2 cars, 1 bus, 1 tv, 667.1ms\n",
      "Speed: 1.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204300.jpg: 384x640 5 cars, 1 bus, 1 traffic light, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204400.jpg: 384x640 1 tv, 668.8ms\n",
      "Speed: 1.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204500.jpg: 384x640 5 cars, 1 bus, 663.8ms\n",
      "Speed: 1.0ms preprocess, 663.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204600.jpg: 384x640 1 tv, 665.4ms\n",
      "Speed: 2.0ms preprocess, 665.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204700.jpg: 384x640 10 cars, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204800.jpg: 384x640 2 cars, 1 bus, 1 tv, 668.1ms\n",
      "Speed: 1.0ms preprocess, 668.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_204900.jpg: 384x640 1 bus, 1 truck, 667.1ms\n",
      "Speed: 1.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205000.jpg: 384x640 1 bus, 1 truck, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205100.jpg: 384x640 1 tv, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205200.jpg: 384x640 4 cars, 1 tv, 667.9ms\n",
      "Speed: 2.0ms preprocess, 667.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205300.jpg: 384x640 2 cars, 1 bus, 1 tv, 665.6ms\n",
      "Speed: 2.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205400.jpg: 384x640 4 cars, 2 buss, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205500.jpg: 384x640 3 cars, 1 bus, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205600.jpg: 384x640 4 cars, 2 buss, 1 tv, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205700.jpg: 384x640 5 cars, 2 buss, 668.2ms\n",
      "Speed: 1.2ms preprocess, 668.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205800.jpg: 384x640 1 tv, 665.7ms\n",
      "Speed: 2.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_205900.jpg: 384x640 8 cars, 1 bus, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210000.jpg: 384x640 4 cars, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210100.jpg: 384x640 1 person, 5 cars, 1 traffic light, 1 tv, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210200.jpg: 384x640 5 cars, 2 buss, 1 tv, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210300.jpg: 384x640 3 cars, 1 tv, 664.2ms\n",
      "Speed: 1.0ms preprocess, 664.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210400.jpg: 384x640 4 cars, 673.3ms\n",
      "Speed: 1.0ms preprocess, 673.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210500.jpg: 384x640 1 car, 1 tv, 671.2ms\n",
      "Speed: 2.0ms preprocess, 671.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210600.jpg: 384x640 8 cars, 2 buss, 1 tv, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210700.jpg: 384x640 1 tv, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210800.jpg: 384x640 7 cars, 1 tv, 665.1ms\n",
      "Speed: 2.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_210900.jpg: 384x640 2 cars, 1 bus, 1 tv, 667.7ms\n",
      "Speed: 2.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211000.jpg: 384x640 1 car, 1 tv, 665.7ms\n",
      "Speed: 2.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211100.jpg: 384x640 4 cars, 2 buss, 662.3ms\n",
      "Speed: 2.0ms preprocess, 662.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211200.jpg: 384x640 1 bus, 1 tv, 668.3ms\n",
      "Speed: 1.0ms preprocess, 668.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211300.jpg: 384x640 6 cars, 1 motorcycle, 1 bus, 1 tv, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211400.jpg: 384x640 2 buss, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211500.jpg: 384x640 1 person, 6 cars, 1 tv, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211600.jpg: 384x640 7 cars, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211700.jpg: 384x640 1 car, 1 tv, 660.6ms\n",
      "Speed: 1.0ms preprocess, 660.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211800.jpg: 384x640 4 cars, 2 buss, 665.8ms\n",
      "Speed: 2.0ms preprocess, 665.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_211900.jpg: 384x640 1 tv, 670.2ms\n",
      "Speed: 2.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212000.jpg: 384x640 5 cars, 1 bus, 666.2ms\n",
      "Speed: 1.0ms preprocess, 666.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212100.jpg: 384x640 4 cars, 1 bus, 661.2ms\n",
      "Speed: 1.0ms preprocess, 661.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212200.jpg: 384x640 3 cars, 2 buss, 1 tv, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212300.jpg: 384x640 5 cars, 2 buss, 1 tv, 661.9ms\n",
      "Speed: 1.0ms preprocess, 661.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212400.jpg: 384x640 4 cars, 699.6ms\n",
      "Speed: 1.0ms preprocess, 699.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212500.jpg: 384x640 6 cars, 1 bus, 1 tv, 677.5ms\n",
      "Speed: 1.0ms preprocess, 677.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212600.jpg: 384x640 1 bus, 1 tv, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212700.jpg: 384x640 6 cars, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212800.jpg: 384x640 3 cars, 1 tv, 673.6ms\n",
      "Speed: 1.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_212900.jpg: 384x640 1 car, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213000.jpg: 384x640 1 car, 1 traffic light, 672.1ms\n",
      "Speed: 1.0ms preprocess, 672.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213100.jpg: 384x640 1 car, 1 tv, 673.1ms\n",
      "Speed: 1.0ms preprocess, 673.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213200.jpg: 384x640 6 cars, 1 bus, 663.7ms\n",
      "Speed: 1.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213300.jpg: 384x640 1 tv, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213400.jpg: 384x640 5 cars, 1 bus, 1 traffic light, 1 tv, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213500.jpg: 384x640 1 car, 664.7ms\n",
      "Speed: 1.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213600.jpg: 384x640 2 cars, 670.2ms\n",
      "Speed: 2.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213700.jpg: 384x640 2 cars, 670.2ms\n",
      "Speed: 1.0ms preprocess, 670.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213800.jpg: 384x640 1 tv, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_213900.jpg: 384x640 3 cars, 1 tv, 668.1ms\n",
      "Speed: 2.0ms preprocess, 668.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214000.jpg: 384x640 2 cars, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214100.jpg: 384x640 10 cars, 1 bus, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214200.jpg: 384x640 1 bus, 1 tv, 671.6ms\n",
      "Speed: 1.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214300.jpg: 384x640 1 person, 7 cars, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214400.jpg: 384x640 6 cars, 1 truck, 1 tv, 668.6ms\n",
      "Speed: 1.0ms preprocess, 668.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214500.jpg: 384x640 2 cars, 666.6ms\n",
      "Speed: 2.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214600.jpg: 384x640 8 cars, 1 bus, 1 traffic light, 668.8ms\n",
      "Speed: 1.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214700.jpg: 384x640 (no detections), 667.1ms\n",
      "Speed: 2.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214800.jpg: 384x640 6 cars, 1 bus, 667.1ms\n",
      "Speed: 2.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_214900.jpg: 384x640 5 cars, 1 tv, 667.7ms\n",
      "Speed: 2.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215000.jpg: 384x640 4 cars, 1 bus, 665.2ms\n",
      "Speed: 1.0ms preprocess, 665.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215100.jpg: 384x640 8 cars, 1 bus, 1 tv, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215200.jpg: 384x640 1 tv, 664.4ms\n",
      "Speed: 1.0ms preprocess, 664.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215300.jpg: 384x640 2 cars, 670.7ms\n",
      "Speed: 1.0ms preprocess, 670.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215400.jpg: 384x640 1 car, 1 tv, 670.7ms\n",
      "Speed: 1.0ms preprocess, 670.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215500.jpg: 384x640 6 cars, 1 bus, 667.6ms\n",
      "Speed: 2.0ms preprocess, 667.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215600.jpg: 384x640 3 cars, 1 bus, 674.3ms\n",
      "Speed: 1.0ms preprocess, 674.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215700.jpg: 384x640 2 cars, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215800.jpg: 384x640 2 cars, 1 traffic light, 663.9ms\n",
      "Speed: 1.0ms preprocess, 663.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_215900.jpg: 384x640 1 bus, 673.0ms\n",
      "Speed: 1.0ms preprocess, 673.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220000.jpg: 384x640 1 car, 1 bus, 669.6ms\n",
      "Speed: 2.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220100.jpg: 384x640 1 tv, 665.6ms\n",
      "Speed: 1.0ms preprocess, 665.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220200.jpg: 384x640 9 cars, 1 tv, 671.8ms\n",
      "Speed: 1.0ms preprocess, 671.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220300.jpg: 384x640 1 person, 3 cars, 1 bus, 1 tv, 670.6ms\n",
      "Speed: 2.0ms preprocess, 670.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220400.jpg: 384x640 6 cars, 1 motorcycle, 667.7ms\n",
      "Speed: 2.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220500.jpg: 384x640 1 person, 2 cars, 1 traffic light, 1 tv, 675.8ms\n",
      "Speed: 1.0ms preprocess, 675.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220600.jpg: 384x640 1 car, 668.8ms\n",
      "Speed: 2.0ms preprocess, 668.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220700.jpg: 384x640 4 cars, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220800.jpg: 384x640 1 tv, 664.9ms\n",
      "Speed: 1.0ms preprocess, 664.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_220900.jpg: 384x640 5 cars, 1 traffic light, 1 tv, 667.7ms\n",
      "Speed: 1.0ms preprocess, 667.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221000.jpg: 384x640 1 person, 3 cars, 1 tv, 659.6ms\n",
      "Speed: 1.0ms preprocess, 659.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221100.jpg: 384x640 2 cars, 1 traffic light, 1 tv, 669.7ms\n",
      "Speed: 1.0ms preprocess, 669.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221200.jpg: 384x640 5 cars, 1 tv, 664.6ms\n",
      "Speed: 2.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221300.jpg: 384x640 1 tv, 661.3ms\n",
      "Speed: 1.0ms preprocess, 661.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221400.jpg: 384x640 4 cars, 1 tv, 661.2ms\n",
      "Speed: 2.0ms preprocess, 661.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221500.jpg: 384x640 2 cars, 1 tv, 666.4ms\n",
      "Speed: 1.0ms preprocess, 666.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221600.jpg: 384x640 7 cars, 665.7ms\n",
      "Speed: 1.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221700.jpg: 384x640 2 cars, 1 bus, 1 tv, 666.6ms\n",
      "Speed: 1.0ms preprocess, 666.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221800.jpg: 384x640 (no detections), 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_221900.jpg: 384x640 4 cars, 1 tv, 664.3ms\n",
      "Speed: 1.0ms preprocess, 664.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222000.jpg: 384x640 (no detections), 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222100.jpg: 384x640 7 cars, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222200.jpg: 384x640 (no detections), 663.7ms\n",
      "Speed: 1.0ms preprocess, 663.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222300.jpg: 384x640 7 cars, 1 tv, 664.6ms\n",
      "Speed: 1.0ms preprocess, 664.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222400.jpg: 384x640 2 cars, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222500.jpg: 384x640 11 cars, 1 bus, 1 tv, 661.2ms\n",
      "Speed: 1.0ms preprocess, 661.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222600.jpg: 384x640 4 cars, 1 bus, 1 truck, 667.2ms\n",
      "Speed: 2.0ms preprocess, 667.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222700.jpg: 384x640 3 cars, 1 bus, 682.1ms\n",
      "Speed: 1.0ms preprocess, 682.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222800.jpg: 384x640 1 car, 666.2ms\n",
      "Speed: 2.0ms preprocess, 666.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_222900.jpg: 384x640 (no detections), 664.7ms\n",
      "Speed: 2.0ms preprocess, 664.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223000.jpg: 384x640 7 cars, 1 traffic light, 663.9ms\n",
      "Speed: 1.0ms preprocess, 663.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223100.jpg: 384x640 1 person, 1 tv, 662.8ms\n",
      "Speed: 1.0ms preprocess, 662.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223200.jpg: 384x640 11 cars, 1 tv, 661.8ms\n",
      "Speed: 1.0ms preprocess, 661.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223300.jpg: 384x640 4 cars, 1 truck, 661.3ms\n",
      "Speed: 2.0ms preprocess, 661.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223400.jpg: 384x640 2 cars, 666.1ms\n",
      "Speed: 1.0ms preprocess, 666.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223500.jpg: 384x640 7 cars, 665.7ms\n",
      "Speed: 2.0ms preprocess, 665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223600.jpg: 384x640 1 tv, 666.7ms\n",
      "Speed: 1.0ms preprocess, 666.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223700.jpg: 384x640 8 cars, 1 tv, 663.6ms\n",
      "Speed: 1.0ms preprocess, 663.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223800.jpg: 384x640 1 tv, 669.8ms\n",
      "Speed: 1.0ms preprocess, 669.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_223900.jpg: 384x640 7 cars, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224000.jpg: 384x640 2 cars, 2 buss, 1 tv, 667.1ms\n",
      "Speed: 2.0ms preprocess, 667.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224100.jpg: 384x640 7 cars, 1 bus, 1 tv, 663.0ms\n",
      "Speed: 1.0ms preprocess, 663.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224200.jpg: 384x640 1 car, 1 tv, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224300.jpg: 384x640 7 cars, 1 bus, 706.6ms\n",
      "Speed: 1.0ms preprocess, 706.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224400.jpg: 384x640 1 car, 1 bus, 1 tv, 670.1ms\n",
      "Speed: 1.0ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224500.jpg: 384x640 6 cars, 671.1ms\n",
      "Speed: 1.0ms preprocess, 671.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224600.jpg: 384x640 1 car, 1 tv, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224700.jpg: 384x640 6 cars, 1 bus, 665.7ms\n",
      "Speed: 2.0ms preprocess, 665.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224800.jpg: 384x640 2 cars, 675.7ms\n",
      "Speed: 1.0ms preprocess, 675.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_224900.jpg: 384x640 1 person, 8 cars, 1 tv, 665.1ms\n",
      "Speed: 2.0ms preprocess, 665.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225000.jpg: 384x640 1 tv, 670.7ms\n",
      "Speed: 1.0ms preprocess, 670.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225100.jpg: 384x640 6 cars, 673.6ms\n",
      "Speed: 1.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225200.jpg: 384x640 2 cars, 1 tv, 673.6ms\n",
      "Speed: 2.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225300.jpg: 384x640 7 cars, 1 bus, 1 traffic light, 1 tv, 676.6ms\n",
      "Speed: 2.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225400.jpg: 384x640 (no detections), 686.5ms\n",
      "Speed: 1.0ms preprocess, 686.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225500.jpg: 384x640 4 cars, 680.6ms\n",
      "Speed: 1.0ms preprocess, 680.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225600.jpg: 384x640 2 cars, 1 bus, 1 tv, 688.6ms\n",
      "Speed: 2.0ms preprocess, 688.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225700.jpg: 384x640 6 cars, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225800.jpg: 384x640 1 car, 1 tv, 670.6ms\n",
      "Speed: 1.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_225900.jpg: 384x640 4 cars, 684.6ms\n",
      "Speed: 2.0ms preprocess, 684.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230000.jpg: 384x640 1 truck, 682.6ms\n",
      "Speed: 1.0ms preprocess, 682.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230100.jpg: 384x640 10 cars, 1 truck, 691.6ms\n",
      "Speed: 1.0ms preprocess, 691.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230200.jpg: 384x640 4 cars, 1 truck, 1 tv, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230300.jpg: 384x640 7 cars, 2 buss, 1 tv, 674.5ms\n",
      "Speed: 2.0ms preprocess, 674.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230400.jpg: 384x640 2 cars, 1 bus, 674.6ms\n",
      "Speed: 2.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230500.jpg: 384x640 5 cars, 1 traffic light, 1 tv, 684.5ms\n",
      "Speed: 1.0ms preprocess, 684.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230600.jpg: 384x640 1 car, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230700.jpg: 384x640 6 cars, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230800.jpg: 384x640 2 cars, 1 bus, 1 tv, 683.5ms\n",
      "Speed: 1.0ms preprocess, 683.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_230900.jpg: 384x640 7 cars, 1 tv, 667.5ms\n",
      "Speed: 1.0ms preprocess, 667.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231000.jpg: 384x640 1 car, 673.6ms\n",
      "Speed: 2.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231100.jpg: 384x640 1 person, 5 cars, 681.5ms\n",
      "Speed: 1.0ms preprocess, 681.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231200.jpg: 384x640 2 cars, 671.5ms\n",
      "Speed: 1.0ms preprocess, 671.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231300.jpg: 384x640 6 cars, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231400.jpg: 384x640 1 car, 1 tv, 676.6ms\n",
      "Speed: 2.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231500.jpg: 384x640 8 cars, 1 truck, 1 traffic light, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231600.jpg: 384x640 3 cars, 678.0ms\n",
      "Speed: 2.0ms preprocess, 678.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231700.jpg: 384x640 2 persons, 6 cars, 1 tv, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231800.jpg: 384x640 3 cars, 676.0ms\n",
      "Speed: 2.0ms preprocess, 676.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_231900.jpg: 384x640 10 cars, 1 tv, 678.0ms\n",
      "Speed: 1.0ms preprocess, 678.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232000.jpg: 384x640 1 car, 1 tv, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232100.jpg: 384x640 5 cars, 1 traffic light, 1 tv, 673.6ms\n",
      "Speed: 2.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232200.jpg: 384x640 3 cars, 1 tv, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232300.jpg: 384x640 7 cars, 1 bus, 1 tv, 682.3ms\n",
      "Speed: 1.0ms preprocess, 682.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232400.jpg: 384x640 1 tv, 681.5ms\n",
      "Speed: 1.0ms preprocess, 681.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232500.jpg: 384x640 7 cars, 667.5ms\n",
      "Speed: 1.0ms preprocess, 667.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232600.jpg: 384x640 1 car, 671.6ms\n",
      "Speed: 2.0ms preprocess, 671.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232700.jpg: 384x640 3 persons, 7 cars, 1 traffic light, 670.6ms\n",
      "Speed: 2.0ms preprocess, 670.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232800.jpg: 384x640 4 cars, 1 bus, 673.5ms\n",
      "Speed: 1.0ms preprocess, 673.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_232900.jpg: 384x640 6 cars, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233000.jpg: 384x640 1 bus, 1 truck, 675.6ms\n",
      "Speed: 2.0ms preprocess, 675.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233100.jpg: 384x640 7 cars, 1 truck, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233200.jpg: 384x640 1 person, 3 cars, 1 tv, 673.6ms\n",
      "Speed: 1.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233300.jpg: 384x640 1 person, 4 cars, 1 traffic light, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233400.jpg: 384x640 5 cars, 1 bus, 671.0ms\n",
      "Speed: 1.0ms preprocess, 671.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233500.jpg: 384x640 1 person, 5 cars, 673.0ms\n",
      "Speed: 1.0ms preprocess, 673.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233600.jpg: 384x640 1 car, 1 tv, 677.0ms\n",
      "Speed: 1.0ms preprocess, 677.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233700.jpg: 384x640 4 cars, 1 truck, 1 tv, 670.0ms\n",
      "Speed: 2.0ms preprocess, 670.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233800.jpg: 384x640 1 tv, 677.1ms\n",
      "Speed: 2.0ms preprocess, 677.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_233900.jpg: 384x640 4 cars, 1 tv, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234000.jpg: 384x640 3 cars, 1 tv, 681.6ms\n",
      "Speed: 1.0ms preprocess, 681.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234100.jpg: 384x640 3 cars, 1 tv, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234200.jpg: 384x640 3 cars, 673.6ms\n",
      "Speed: 1.0ms preprocess, 673.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234300.jpg: 384x640 6 cars, 1 tv, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234400.jpg: 384x640 2 cars, 1 tv, 673.6ms\n",
      "Speed: 1.0ms preprocess, 673.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234500.jpg: 384x640 8 cars, 1 tv, 672.6ms\n",
      "Speed: 1.0ms preprocess, 672.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234600.jpg: 384x640 3 cars, 1 tv, 677.6ms\n",
      "Speed: 1.0ms preprocess, 677.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234700.jpg: 384x640 8 cars, 1 tv, 672.5ms\n",
      "Speed: 1.0ms preprocess, 672.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234800.jpg: 384x640 1 car, 1 tv, 669.6ms\n",
      "Speed: 1.0ms preprocess, 669.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_234900.jpg: 384x640 8 cars, 1 tv, 676.6ms\n",
      "Speed: 1.0ms preprocess, 676.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235000.jpg: 384x640 1 tv, 674.6ms\n",
      "Speed: 1.0ms preprocess, 674.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235100.jpg: 384x640 6 cars, 1 tv, 673.0ms\n",
      "Speed: 1.0ms preprocess, 673.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235200.jpg: 384x640 1 tv, 679.0ms\n",
      "Speed: 2.0ms preprocess, 679.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235300.jpg: 384x640 4 cars, 1 tv, 687.1ms\n",
      "Speed: 2.0ms preprocess, 687.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235400.jpg: 384x640 1 car, 1 tv, 716.6ms\n",
      "Speed: 2.0ms preprocess, 716.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235500.jpg: 384x640 7 cars, 1 tv, 690.7ms\n",
      "Speed: 1.0ms preprocess, 690.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235600.jpg: 384x640 1 person, 5 cars, 1 tv, 693.6ms\n",
      "Speed: 1.0ms preprocess, 693.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235700.jpg: 384x640 4 cars, 1 tv, 687.6ms\n",
      "Speed: 2.0ms preprocess, 687.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235800.jpg: 384x640 2 cars, 1 tv, 680.6ms\n",
      "Speed: 2.0ms preprocess, 680.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "image 1/1 F:\\src\\JPT\\shibuya-scramble\\notebooks\\..\\data\\20240512\\20240512_235900.jpg: 384x640 7 cars, 1 tv, 683.6ms\n",
      "Speed: 1.0ms preprocess, 683.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mF:\\src\\JPT\\shibuya-scramble\\runs\\detect\\predict\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 20240512の概要",
   "id": "c7b1051225a68a17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:01:34.171925Z",
     "start_time": "2024-06-10T12:01:34.168621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"時間帯ごとの小計:\")\n",
    "for k, v in sum_dict.items():\n",
    "    print(f\"[{k:10}], {dict(v)}\")\n",
    "    print(f\"[{k:10}の合計] {sum(v.values()):4}\\t[1時間あたりの平均台数] {sum(v.values()) / len(v):7.2f}\")"
   ],
   "id": "4f4de9ff8ad2a25c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "時間帯ごとの小計:\n",
      "[person    ], {0: 2, 1: 0, 2: 3, 3: 0, 4: 2, 5: 6, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0}\n",
      "[person    の合計]   14\t[1時間あたりの平均台数]    0.58\n",
      "[bicycle   ], {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0}\n",
      "[bicycle   の合計]    0\t[1時間あたりの平均台数]    0.00\n",
      "[car       ], {0: 42, 1: 342, 2: 20, 3: 0, 4: 155, 5: 8, 6: 2, 7: 5, 8: 1, 9: 31, 10: 43, 11: 0, 12: 59, 13: 111, 14: 50, 15: 129, 16: 103, 17: 212, 18: 22, 19: 32, 20: 8, 21: 0, 22: 17, 23: 30}\n",
      "[car       の合計] 1422\t[1時間あたりの平均台数]   59.25\n",
      "[motorcycle], {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0}\n",
      "[motorcycleの合計]    0\t[1時間あたりの平均台数]    0.00\n",
      "[bus       ], {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 3, 8: 0, 9: 5, 10: 12, 11: 12, 12: 9, 13: 21, 14: 4, 15: 26, 16: 6, 17: 2, 18: 3, 19: 0, 20: 1, 21: 1, 22: 0, 23: 0}\n",
      "[bus       の合計]  106\t[1時間あたりの平均台数]    4.42\n",
      "[truck     ], {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0}\n",
      "[truck     の合計]    1\t[1時間あたりの平均台数]    0.04\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:01:34.673759Z",
     "start_time": "2024-06-10T12:01:34.473645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "\n",
    "df = pd.DataFrame({k: v.values() for k, v in sum_dict.items()})\n",
    "ax = sns.lineplot(data=df)\n",
    "\n",
    "# 日本語の表示ができないため、英語を使う\n",
    "ax.set_xlabel(\"hour\")\n",
    "ax.set_ylabel(\"amounts\")\n",
    "\n",
    "# 横軸を1時間刻みにして0-23時の間を表示する\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(base=1))\n",
    "ax.set_xticks(range(24))\n",
    "ax.set_xticklabels([f\"{str(i)}\" for i in range(24)])\n",
    "plt.xlim(0, 24)"
   ],
   "id": "35d2d14410ab56a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 24.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "20240512に存在する画像から物体検出を行った。\n",
    "/runs に生成された画像を確認すると、正誤はともかく `cars`/`trucks`/`bus`/`motorcycles` などが検出できている。  \n",
    "このままで顧客の要件を満たすかわからないため、目視で確認した範囲で見つけた　`乗用車`/`タクシー`/`バス`/`ゴミ収集車`/`トラック`/`救急車`/`パトカー`/`原付` を分類する方が望ましいか顧客に確認を行う。(依頼: 2024/06/03)\n"
   ],
   "id": "2cc9debd99abc6ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:55:45.325276Z",
     "start_time": "2024-06-10T11:55:45.319336Z"
    }
   },
   "cell_type": "code",
   "source": "results[0].boxes",
   "id": "50f7583a72bf46b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([ 2.,  2.,  2.,  2.,  2.,  2.,  2., 62.])\n",
       "conf: tensor([0.8328, 0.7948, 0.7751, 0.7239, 0.7093, 0.7076, 0.6969, 0.5806])\n",
       "data: tensor([[2.4772e+02, 1.1513e+02, 3.0480e+02, 1.6008e+02, 8.3283e-01, 2.0000e+00],\n",
       "        [4.9505e+02, 3.7752e+02, 5.9677e+02, 4.4270e+02, 7.9480e-01, 2.0000e+00],\n",
       "        [3.0205e+02, 1.6473e+02, 3.6058e+02, 2.0996e+02, 7.7513e-01, 2.0000e+00],\n",
       "        [3.6346e+02, 1.5538e+02, 4.1836e+02, 2.0101e+02, 7.2394e-01, 2.0000e+00],\n",
       "        [9.3815e+02, 5.4476e+02, 1.0425e+03, 6.3433e+02, 7.0935e-01, 2.0000e+00],\n",
       "        [0.0000e+00, 4.0002e+02, 8.4933e+01, 4.5510e+02, 7.0759e-01, 2.0000e+00],\n",
       "        [2.0748e+02, 8.7475e+01, 2.5322e+02, 1.3114e+02, 6.9686e-01, 2.0000e+00],\n",
       "        [5.5341e+02, 4.1734e+01, 7.0533e+02, 1.5008e+02, 5.8059e-01, 6.2000e+01]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (720, 1280)\n",
       "shape: torch.Size([8, 6])\n",
       "xywh: tensor([[276.2595, 137.6049,  57.0725,  44.9407],\n",
       "        [545.9097, 410.1072, 101.7113,  65.1838],\n",
       "        [331.3159, 187.3441,  58.5253,  45.2289],\n",
       "        [390.9090, 178.1974,  54.9046,  45.6279],\n",
       "        [990.3085, 589.5454, 104.3167,  89.5688],\n",
       "        [ 42.4665, 427.5629,  84.9330,  55.0839],\n",
       "        [230.3505, 109.3061,  45.7372,  43.6616],\n",
       "        [629.3671,  95.9080, 151.9204, 108.3473]])\n",
       "xywhn: tensor([[0.2158, 0.1911, 0.0446, 0.0624],\n",
       "        [0.4265, 0.5696, 0.0795, 0.0905],\n",
       "        [0.2588, 0.2602, 0.0457, 0.0628],\n",
       "        [0.3054, 0.2475, 0.0429, 0.0634],\n",
       "        [0.7737, 0.8188, 0.0815, 0.1244],\n",
       "        [0.0332, 0.5938, 0.0664, 0.0765],\n",
       "        [0.1800, 0.1518, 0.0357, 0.0606],\n",
       "        [0.4917, 0.1332, 0.1187, 0.1505]])\n",
       "xyxy: tensor([[ 247.7232,  115.1346,  304.7957,  160.0753],\n",
       "        [ 495.0541,  377.5153,  596.7654,  442.6992],\n",
       "        [ 302.0532,  164.7296,  360.5786,  209.9586],\n",
       "        [ 363.4567,  155.3835,  418.3613,  201.0114],\n",
       "        [ 938.1501,  544.7610, 1042.4668,  634.3298],\n",
       "        [   0.0000,  400.0210,   84.9330,  455.1049],\n",
       "        [ 207.4819,   87.4753,  253.2191,  131.1369],\n",
       "        [ 553.4069,   41.7343,  705.3273,  150.0816]])\n",
       "xyxyn: tensor([[0.1935, 0.1599, 0.2381, 0.2223],\n",
       "        [0.3868, 0.5243, 0.4662, 0.6149],\n",
       "        [0.2360, 0.2288, 0.2817, 0.2916],\n",
       "        [0.2840, 0.2158, 0.3268, 0.2792],\n",
       "        [0.7329, 0.7566, 0.8144, 0.8810],\n",
       "        [0.0000, 0.5556, 0.0664, 0.6321],\n",
       "        [0.1621, 0.1215, 0.1978, 0.1821],\n",
       "        [0.4323, 0.0580, 0.5510, 0.2084]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
